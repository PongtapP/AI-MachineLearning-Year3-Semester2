{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d20AgNdoJ3zm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "Adam = tf.keras.optimizers.Adam\n",
        "to_categorical = tf.keras.utils.to_categorical\n",
        "ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "load_img = tf.keras.preprocessing.image.load_img\n",
        "img_to_array = tf.keras.preprocessing.image.img_to_array\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "from plotly import subplots\n",
        "import plotly\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_ROWS = 28\n",
        "IMG_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "VAL_SIZE = 0.2\n",
        "RANDOM_STATE = 99\n",
        "BATCH_SIZE = 256"
      ],
      "metadata": {
        "id": "ETbhDUKkJ59h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data,y),(test_data,y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(\"Fashion MNIST train - rows:\",train_data.shape[0],\" columns:\",train_data.shape[1],\" rows:\",train_data.shape[2])\n",
        "print(\"Fashion MNIST test - rows:\",test_data.shape[0],\" columns:\",test_data.shape[1],\" rows:\",train_data.shape[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUxT-MRjJ77C",
        "outputId": "fc98f896-4142-4524-b5ed-1eefdb47ce88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Fashion MNIST train - rows: 60000  columns: 28  rows: 28\n",
            "Fashion MNIST test - rows: 10000  columns: 28  rows: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape, test_data.shape)\n",
        "\n",
        "train_data = train_data.reshape((train_data.shape[0], 28, 28, 1))\n",
        "test_data = test_data.reshape((test_data.shape[0], 28, 28, 1))\n",
        "\n",
        "print(train_data.shape, test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c9qwhfdKB0M",
        "outputId": "03f33661-9664-4eb0-94dc-8657c0dce60f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (10000, 28, 28)\n",
            "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data/255.0\n",
        "test_data = test_data/255.0"
      ],
      "metadata": {
        "id": "LWBBRrUsKDDb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "uMIVUUpwKEoq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_val,y_train,y_val = train_test_split(train_data,y,test_size=VAL_SIZE,random_state=RANDOM_STATE)\n",
        "\n",
        "x_train.shape,x_val.shape,y_train.shape,y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-g0mNJ3KJqh",
        "outputId": "df5a46f5-166d-475d-cb24-e3c50bcccec4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 28, 28, 1), (12000, 28, 28, 1), (48000, 10), (12000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=0.05,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.05\n",
        ")\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "x32__KxoKSPF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = sequential()\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "#1.CNN LAYER\n",
        "model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),padding='Same',input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "#2.CNN LAYER\n",
        "model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),padding='Same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "#3.CNN LAYER\n",
        "model.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding='Same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "#4.CNN LAYER\n",
        "model.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding='Same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "#FULLY CONNECTES LAYER\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "#OUTPUT LAYER\n",
        "model.add(tf.keras.layers.Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "wRhL30JCKZEq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "id": "6bIzknzgKaMF",
        "outputId": "bd936bc5-a81d-4308-f4d2-64e1576eab4b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m803,072\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,570\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">803,072</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m872,426\u001b[0m (3.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">872,426</span> (3.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m871,530\u001b[0m (3.32 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">871,530</span> (3.32 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NO_EPOCH = 200\n",
        "history = model.fit(datagen.flow(x_train,y_train,batch_size=BATCH_SIZE),shuffle=True,epochs=NO_EPOCH,verbose=1,validation_data=(x_val,y_val),steps_per_epoch=x_train.shape[0] // BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7C20Y1XKb7k",
        "outputId": "c1d402e3-4116-4a26-d5c2-83ffddd21c3a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 163ms/step - accuracy: 0.6037 - loss: 1.0885 - val_accuracy: 0.1512 - val_loss: 2.8556\n",
            "Epoch 2/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8516 - loss: 0.5298 - val_accuracy: 0.1422 - val_loss: 2.8665\n",
            "Epoch 3/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.7734 - loss: 0.5910 - val_accuracy: 0.4679 - val_loss: 1.9658\n",
            "Epoch 4/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8008 - loss: 0.5053 - val_accuracy: 0.4663 - val_loss: 1.9429\n",
            "Epoch 5/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.8041 - loss: 0.5108 - val_accuracy: 0.7513 - val_loss: 0.6661\n",
            "Epoch 6/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8516 - loss: 0.4717 - val_accuracy: 0.7469 - val_loss: 0.6823\n",
            "Epoch 7/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.8257 - loss: 0.4592 - val_accuracy: 0.8340 - val_loss: 0.4507\n",
            "Epoch 8/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8477 - loss: 0.3926 - val_accuracy: 0.8223 - val_loss: 0.4797\n",
            "Epoch 9/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 81ms/step - accuracy: 0.8388 - loss: 0.4298 - val_accuracy: 0.8900 - val_loss: 0.2976\n",
            "Epoch 10/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8086 - loss: 0.4845 - val_accuracy: 0.8873 - val_loss: 0.3051\n",
            "Epoch 11/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.8523 - loss: 0.4023 - val_accuracy: 0.8848 - val_loss: 0.3033\n",
            "Epoch 12/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8398 - loss: 0.3990 - val_accuracy: 0.8862 - val_loss: 0.2985\n",
            "Epoch 13/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.8563 - loss: 0.3861 - val_accuracy: 0.8880 - val_loss: 0.3026\n",
            "Epoch 14/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8398 - loss: 0.4028 - val_accuracy: 0.8893 - val_loss: 0.2961\n",
            "Epoch 15/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.8606 - loss: 0.3762 - val_accuracy: 0.8827 - val_loss: 0.3177\n",
            "Epoch 16/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8789 - loss: 0.3457 - val_accuracy: 0.8812 - val_loss: 0.3248\n",
            "Epoch 17/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 82ms/step - accuracy: 0.8633 - loss: 0.3689 - val_accuracy: 0.9032 - val_loss: 0.2612\n",
            "Epoch 18/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8789 - loss: 0.2905 - val_accuracy: 0.9061 - val_loss: 0.2541\n",
            "Epoch 19/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 97ms/step - accuracy: 0.8657 - loss: 0.3612 - val_accuracy: 0.8973 - val_loss: 0.2673\n",
            "Epoch 20/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8555 - loss: 0.3948 - val_accuracy: 0.8989 - val_loss: 0.2644\n",
            "Epoch 21/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 88ms/step - accuracy: 0.8731 - loss: 0.3413 - val_accuracy: 0.9049 - val_loss: 0.2465\n",
            "Epoch 22/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8477 - loss: 0.4058 - val_accuracy: 0.9038 - val_loss: 0.2493\n",
            "Epoch 23/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 81ms/step - accuracy: 0.8743 - loss: 0.3382 - val_accuracy: 0.9142 - val_loss: 0.2341\n",
            "Epoch 24/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8789 - loss: 0.3245 - val_accuracy: 0.9139 - val_loss: 0.2361\n",
            "Epoch 25/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 80ms/step - accuracy: 0.8767 - loss: 0.3326 - val_accuracy: 0.9136 - val_loss: 0.2335\n",
            "Epoch 26/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8945 - loss: 0.3017 - val_accuracy: 0.9142 - val_loss: 0.2348\n",
            "Epoch 27/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 82ms/step - accuracy: 0.8814 - loss: 0.3216 - val_accuracy: 0.9113 - val_loss: 0.2378\n",
            "Epoch 28/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8945 - loss: 0.3120 - val_accuracy: 0.9128 - val_loss: 0.2339\n",
            "Epoch 29/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 85ms/step - accuracy: 0.8818 - loss: 0.3192 - val_accuracy: 0.9165 - val_loss: 0.2282\n",
            "Epoch 30/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.3162 - val_accuracy: 0.9166 - val_loss: 0.2274\n",
            "Epoch 31/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 80ms/step - accuracy: 0.8799 - loss: 0.3172 - val_accuracy: 0.9166 - val_loss: 0.2253\n",
            "Epoch 32/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8789 - loss: 0.2981 - val_accuracy: 0.9171 - val_loss: 0.2238\n",
            "Epoch 33/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 81ms/step - accuracy: 0.8836 - loss: 0.3100 - val_accuracy: 0.9147 - val_loss: 0.2289\n",
            "Epoch 34/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8945 - loss: 0.2447 - val_accuracy: 0.9155 - val_loss: 0.2297\n",
            "Epoch 35/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 85ms/step - accuracy: 0.8869 - loss: 0.3072 - val_accuracy: 0.9175 - val_loss: 0.2270\n",
            "Epoch 36/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 0.4159 - val_accuracy: 0.9189 - val_loss: 0.2230\n",
            "Epoch 37/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.8910 - loss: 0.2924 - val_accuracy: 0.9106 - val_loss: 0.2411\n",
            "Epoch 38/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9180 - loss: 0.3100 - val_accuracy: 0.9107 - val_loss: 0.2382\n",
            "Epoch 39/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.8896 - loss: 0.2973 - val_accuracy: 0.9135 - val_loss: 0.2326\n",
            "Epoch 40/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8867 - loss: 0.3395 - val_accuracy: 0.9156 - val_loss: 0.2257\n",
            "Epoch 41/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 80ms/step - accuracy: 0.8938 - loss: 0.2858 - val_accuracy: 0.9178 - val_loss: 0.2210\n",
            "Epoch 42/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8672 - loss: 0.3451 - val_accuracy: 0.9168 - val_loss: 0.2229\n",
            "Epoch 43/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.8924 - loss: 0.2878 - val_accuracy: 0.9198 - val_loss: 0.2188\n",
            "Epoch 44/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9141 - loss: 0.2437 - val_accuracy: 0.9206 - val_loss: 0.2184\n",
            "Epoch 45/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.8919 - loss: 0.2858 - val_accuracy: 0.9217 - val_loss: 0.2087\n",
            "Epoch 46/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9102 - loss: 0.2751 - val_accuracy: 0.9215 - val_loss: 0.2094\n",
            "Epoch 47/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.8921 - loss: 0.2880 - val_accuracy: 0.9222 - val_loss: 0.2077\n",
            "Epoch 48/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8750 - loss: 0.3315 - val_accuracy: 0.9234 - val_loss: 0.2055\n",
            "Epoch 49/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 80ms/step - accuracy: 0.8936 - loss: 0.2823 - val_accuracy: 0.9191 - val_loss: 0.2150\n",
            "Epoch 50/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9297 - loss: 0.2108 - val_accuracy: 0.9186 - val_loss: 0.2166\n",
            "Epoch 51/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.8954 - loss: 0.2809 - val_accuracy: 0.9247 - val_loss: 0.2054\n",
            "Epoch 52/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8867 - loss: 0.3257 - val_accuracy: 0.9247 - val_loss: 0.2051\n",
            "Epoch 53/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 81ms/step - accuracy: 0.8949 - loss: 0.2797 - val_accuracy: 0.9234 - val_loss: 0.2058\n",
            "Epoch 54/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8828 - loss: 0.3424 - val_accuracy: 0.9233 - val_loss: 0.2067\n",
            "Epoch 55/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9001 - loss: 0.2706 - val_accuracy: 0.9170 - val_loss: 0.2191\n",
            "Epoch 56/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9023 - loss: 0.2289 - val_accuracy: 0.9175 - val_loss: 0.2167\n",
            "Epoch 57/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 80ms/step - accuracy: 0.8984 - loss: 0.2763 - val_accuracy: 0.9258 - val_loss: 0.2014\n",
            "Epoch 58/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9180 - loss: 0.2537 - val_accuracy: 0.9260 - val_loss: 0.2021\n",
            "Epoch 59/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 81ms/step - accuracy: 0.8992 - loss: 0.2724 - val_accuracy: 0.9262 - val_loss: 0.1989\n",
            "Epoch 60/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2450 - val_accuracy: 0.9273 - val_loss: 0.2001\n",
            "Epoch 61/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 90ms/step - accuracy: 0.8974 - loss: 0.2694 - val_accuracy: 0.9257 - val_loss: 0.2019\n",
            "Epoch 62/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9297 - loss: 0.2009 - val_accuracy: 0.9253 - val_loss: 0.2017\n",
            "Epoch 63/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.9018 - loss: 0.2636 - val_accuracy: 0.9243 - val_loss: 0.2099\n",
            "Epoch 64/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.1877 - val_accuracy: 0.9235 - val_loss: 0.2121\n",
            "Epoch 65/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 81ms/step - accuracy: 0.9016 - loss: 0.2643 - val_accuracy: 0.9227 - val_loss: 0.2046\n",
            "Epoch 66/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8945 - loss: 0.3316 - val_accuracy: 0.9234 - val_loss: 0.2037\n",
            "Epoch 67/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9024 - loss: 0.2578 - val_accuracy: 0.9260 - val_loss: 0.2075\n",
            "Epoch 68/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9180 - loss: 0.2355 - val_accuracy: 0.9262 - val_loss: 0.2068\n",
            "Epoch 69/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 80ms/step - accuracy: 0.9024 - loss: 0.2623 - val_accuracy: 0.9263 - val_loss: 0.1974\n",
            "Epoch 70/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9023 - loss: 0.2523 - val_accuracy: 0.9264 - val_loss: 0.1977\n",
            "Epoch 71/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.9032 - loss: 0.2578 - val_accuracy: 0.9256 - val_loss: 0.1990\n",
            "Epoch 72/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9219 - loss: 0.2102 - val_accuracy: 0.9252 - val_loss: 0.1986\n",
            "Epoch 73/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 86ms/step - accuracy: 0.9044 - loss: 0.2594 - val_accuracy: 0.9252 - val_loss: 0.2010\n",
            "Epoch 74/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8984 - loss: 0.2445 - val_accuracy: 0.9259 - val_loss: 0.2018\n",
            "Epoch 75/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.9030 - loss: 0.2594 - val_accuracy: 0.9268 - val_loss: 0.1959\n",
            "Epoch 76/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8633 - loss: 0.3331 - val_accuracy: 0.9289 - val_loss: 0.1922\n",
            "Epoch 77/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 83ms/step - accuracy: 0.9024 - loss: 0.2623 - val_accuracy: 0.9287 - val_loss: 0.1939\n",
            "Epoch 78/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8594 - loss: 0.3113 - val_accuracy: 0.9286 - val_loss: 0.1948\n",
            "Epoch 79/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9055 - loss: 0.2548 - val_accuracy: 0.9258 - val_loss: 0.1989\n",
            "Epoch 80/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8945 - loss: 0.2802 - val_accuracy: 0.9262 - val_loss: 0.1982\n",
            "Epoch 81/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 83ms/step - accuracy: 0.9034 - loss: 0.2585 - val_accuracy: 0.9280 - val_loss: 0.1937\n",
            "Epoch 82/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9023 - loss: 0.2381 - val_accuracy: 0.9291 - val_loss: 0.1910\n",
            "Epoch 83/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 83ms/step - accuracy: 0.9054 - loss: 0.2523 - val_accuracy: 0.9239 - val_loss: 0.2014\n",
            "Epoch 84/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9219 - loss: 0.2537 - val_accuracy: 0.9231 - val_loss: 0.2021\n",
            "Epoch 85/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9089 - loss: 0.2463 - val_accuracy: 0.9319 - val_loss: 0.1863\n",
            "Epoch 86/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9062 - loss: 0.2584 - val_accuracy: 0.9312 - val_loss: 0.1867\n",
            "Epoch 87/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 83ms/step - accuracy: 0.9086 - loss: 0.2454 - val_accuracy: 0.9335 - val_loss: 0.1844\n",
            "Epoch 88/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2313 - val_accuracy: 0.9333 - val_loss: 0.1853\n",
            "Epoch 89/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 81ms/step - accuracy: 0.9059 - loss: 0.2463 - val_accuracy: 0.9298 - val_loss: 0.1918\n",
            "Epoch 90/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9141 - loss: 0.2286 - val_accuracy: 0.9314 - val_loss: 0.1893\n",
            "Epoch 91/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9053 - loss: 0.2531 - val_accuracy: 0.9299 - val_loss: 0.1913\n",
            "Epoch 92/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8867 - loss: 0.2942 - val_accuracy: 0.9290 - val_loss: 0.1913\n",
            "Epoch 93/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 83ms/step - accuracy: 0.9111 - loss: 0.2440 - val_accuracy: 0.9306 - val_loss: 0.1870\n",
            "Epoch 94/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.1923 - val_accuracy: 0.9302 - val_loss: 0.1868\n",
            "Epoch 95/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 85ms/step - accuracy: 0.9070 - loss: 0.2455 - val_accuracy: 0.9283 - val_loss: 0.1930\n",
            "Epoch 96/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9453 - loss: 0.1638 - val_accuracy: 0.9277 - val_loss: 0.1935\n",
            "Epoch 97/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.9096 - loss: 0.2443 - val_accuracy: 0.9290 - val_loss: 0.1912\n",
            "Epoch 98/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8906 - loss: 0.2593 - val_accuracy: 0.9298 - val_loss: 0.1901\n",
            "Epoch 99/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 0.9125 - loss: 0.2351 - val_accuracy: 0.9298 - val_loss: 0.1917\n",
            "Epoch 100/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9023 - loss: 0.3094 - val_accuracy: 0.9296 - val_loss: 0.1922\n",
            "Epoch 101/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 81ms/step - accuracy: 0.9102 - loss: 0.2409 - val_accuracy: 0.9346 - val_loss: 0.1839\n",
            "Epoch 102/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9336 - loss: 0.1815 - val_accuracy: 0.9352 - val_loss: 0.1834\n",
            "Epoch 103/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9108 - loss: 0.2376 - val_accuracy: 0.9243 - val_loss: 0.2067\n",
            "Epoch 104/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9219 - loss: 0.2155 - val_accuracy: 0.9245 - val_loss: 0.2064\n",
            "Epoch 105/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.9118 - loss: 0.2373 - val_accuracy: 0.9224 - val_loss: 0.2015\n",
            "Epoch 106/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8750 - loss: 0.3011 - val_accuracy: 0.9222 - val_loss: 0.2024\n",
            "Epoch 107/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9107 - loss: 0.2430 - val_accuracy: 0.9283 - val_loss: 0.1950\n",
            "Epoch 108/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9180 - loss: 0.2013 - val_accuracy: 0.9277 - val_loss: 0.1952\n",
            "Epoch 109/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.9113 - loss: 0.2367 - val_accuracy: 0.9308 - val_loss: 0.1921\n",
            "Epoch 110/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9102 - loss: 0.2693 - val_accuracy: 0.9309 - val_loss: 0.1928\n",
            "Epoch 111/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9119 - loss: 0.2344 - val_accuracy: 0.9320 - val_loss: 0.1874\n",
            "Epoch 112/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9336 - loss: 0.1813 - val_accuracy: 0.9325 - val_loss: 0.1875\n",
            "Epoch 113/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 86ms/step - accuracy: 0.9139 - loss: 0.2335 - val_accuracy: 0.9290 - val_loss: 0.1927\n",
            "Epoch 114/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9180 - loss: 0.2268 - val_accuracy: 0.9286 - val_loss: 0.1932\n",
            "Epoch 115/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 82ms/step - accuracy: 0.9121 - loss: 0.2364 - val_accuracy: 0.9313 - val_loss: 0.1894\n",
            "Epoch 116/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9141 - loss: 0.2338 - val_accuracy: 0.9297 - val_loss: 0.1906\n",
            "Epoch 117/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9113 - loss: 0.2348 - val_accuracy: 0.9313 - val_loss: 0.1838\n",
            "Epoch 118/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9062 - loss: 0.2975 - val_accuracy: 0.9322 - val_loss: 0.1819\n",
            "Epoch 119/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9131 - loss: 0.2299 - val_accuracy: 0.9329 - val_loss: 0.1838\n",
            "Epoch 120/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9102 - loss: 0.2234 - val_accuracy: 0.9327 - val_loss: 0.1841\n",
            "Epoch 121/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9141 - loss: 0.2296 - val_accuracy: 0.9248 - val_loss: 0.2066\n",
            "Epoch 122/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9102 - loss: 0.2216 - val_accuracy: 0.9246 - val_loss: 0.2082\n",
            "Epoch 123/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9126 - loss: 0.2318 - val_accuracy: 0.9218 - val_loss: 0.2097\n",
            "Epoch 124/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8984 - loss: 0.3013 - val_accuracy: 0.9243 - val_loss: 0.2035\n",
            "Epoch 125/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 82ms/step - accuracy: 0.9156 - loss: 0.2280 - val_accuracy: 0.9320 - val_loss: 0.1848\n",
            "Epoch 126/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8750 - loss: 0.3226 - val_accuracy: 0.9324 - val_loss: 0.1843\n",
            "Epoch 127/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 0.9142 - loss: 0.2313 - val_accuracy: 0.9333 - val_loss: 0.1825\n",
            "Epoch 128/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8711 - loss: 0.3203 - val_accuracy: 0.9338 - val_loss: 0.1824\n",
            "Epoch 129/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.9150 - loss: 0.2281 - val_accuracy: 0.9354 - val_loss: 0.1778\n",
            "Epoch 130/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9102 - loss: 0.2205 - val_accuracy: 0.9336 - val_loss: 0.1803\n",
            "Epoch 131/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 86ms/step - accuracy: 0.9144 - loss: 0.2263 - val_accuracy: 0.9322 - val_loss: 0.1820\n",
            "Epoch 132/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9180 - loss: 0.2317 - val_accuracy: 0.9337 - val_loss: 0.1803\n",
            "Epoch 133/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9117 - loss: 0.2305 - val_accuracy: 0.9322 - val_loss: 0.1823\n",
            "Epoch 134/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9102 - loss: 0.2421 - val_accuracy: 0.9325 - val_loss: 0.1829\n",
            "Epoch 135/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 86ms/step - accuracy: 0.9142 - loss: 0.2236 - val_accuracy: 0.9275 - val_loss: 0.1949\n",
            "Epoch 136/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9062 - loss: 0.2382 - val_accuracy: 0.9264 - val_loss: 0.1977\n",
            "Epoch 137/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9129 - loss: 0.2343 - val_accuracy: 0.9329 - val_loss: 0.1829\n",
            "Epoch 138/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9180 - loss: 0.2468 - val_accuracy: 0.9327 - val_loss: 0.1841\n",
            "Epoch 139/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9184 - loss: 0.2209 - val_accuracy: 0.9347 - val_loss: 0.1773\n",
            "Epoch 140/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9297 - loss: 0.1856 - val_accuracy: 0.9348 - val_loss: 0.1775\n",
            "Epoch 141/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.9167 - loss: 0.2205 - val_accuracy: 0.9274 - val_loss: 0.1969\n",
            "Epoch 142/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9336 - loss: 0.2072 - val_accuracy: 0.9293 - val_loss: 0.1957\n",
            "Epoch 143/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9155 - loss: 0.2256 - val_accuracy: 0.9358 - val_loss: 0.1775\n",
            "Epoch 144/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9102 - loss: 0.2040 - val_accuracy: 0.9353 - val_loss: 0.1796\n",
            "Epoch 145/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9191 - loss: 0.2177 - val_accuracy: 0.9314 - val_loss: 0.1885\n",
            "Epoch 146/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9023 - loss: 0.2582 - val_accuracy: 0.9317 - val_loss: 0.1882\n",
            "Epoch 147/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 86ms/step - accuracy: 0.9198 - loss: 0.2194 - val_accuracy: 0.9389 - val_loss: 0.1702\n",
            "Epoch 148/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8867 - loss: 0.2645 - val_accuracy: 0.9383 - val_loss: 0.1721\n",
            "Epoch 149/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.9189 - loss: 0.2150 - val_accuracy: 0.9276 - val_loss: 0.1978\n",
            "Epoch 150/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8984 - loss: 0.3252 - val_accuracy: 0.9277 - val_loss: 0.1968\n",
            "Epoch 151/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9196 - loss: 0.2219 - val_accuracy: 0.9335 - val_loss: 0.1805\n",
            "Epoch 152/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8984 - loss: 0.2196 - val_accuracy: 0.9331 - val_loss: 0.1802\n",
            "Epoch 153/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 88ms/step - accuracy: 0.9178 - loss: 0.2207 - val_accuracy: 0.9307 - val_loss: 0.1837\n",
            "Epoch 154/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9023 - loss: 0.2171 - val_accuracy: 0.9314 - val_loss: 0.1831\n",
            "Epoch 155/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 83ms/step - accuracy: 0.9174 - loss: 0.2232 - val_accuracy: 0.9351 - val_loss: 0.1802\n",
            "Epoch 156/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9297 - loss: 0.1734 - val_accuracy: 0.9349 - val_loss: 0.1802\n",
            "Epoch 157/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 83ms/step - accuracy: 0.9189 - loss: 0.2221 - val_accuracy: 0.9335 - val_loss: 0.1812\n",
            "Epoch 158/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.1554 - val_accuracy: 0.9329 - val_loss: 0.1829\n",
            "Epoch 159/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.9172 - loss: 0.2159 - val_accuracy: 0.9305 - val_loss: 0.1891\n",
            "Epoch 160/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9258 - loss: 0.2390 - val_accuracy: 0.9302 - val_loss: 0.1889\n",
            "Epoch 161/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 81ms/step - accuracy: 0.9211 - loss: 0.2134 - val_accuracy: 0.9375 - val_loss: 0.1748\n",
            "Epoch 162/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9180 - loss: 0.2064 - val_accuracy: 0.9367 - val_loss: 0.1748\n",
            "Epoch 163/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 81ms/step - accuracy: 0.9159 - loss: 0.2224 - val_accuracy: 0.9325 - val_loss: 0.1841\n",
            "Epoch 164/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9258 - loss: 0.1864 - val_accuracy: 0.9327 - val_loss: 0.1845\n",
            "Epoch 165/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.9175 - loss: 0.2207 - val_accuracy: 0.9342 - val_loss: 0.1823\n",
            "Epoch 166/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2172 - val_accuracy: 0.9331 - val_loss: 0.1858\n",
            "Epoch 167/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 82ms/step - accuracy: 0.9172 - loss: 0.2236 - val_accuracy: 0.9364 - val_loss: 0.1785\n",
            "Epoch 168/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9297 - loss: 0.1876 - val_accuracy: 0.9365 - val_loss: 0.1776\n",
            "Epoch 169/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.9202 - loss: 0.2146 - val_accuracy: 0.9382 - val_loss: 0.1730\n",
            "Epoch 170/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9336 - loss: 0.2104 - val_accuracy: 0.9382 - val_loss: 0.1737\n",
            "Epoch 171/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 81ms/step - accuracy: 0.9206 - loss: 0.2125 - val_accuracy: 0.9317 - val_loss: 0.1864\n",
            "Epoch 172/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9414 - loss: 0.1811 - val_accuracy: 0.9317 - val_loss: 0.1857\n",
            "Epoch 173/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 83ms/step - accuracy: 0.9214 - loss: 0.2144 - val_accuracy: 0.9369 - val_loss: 0.1770\n",
            "Epoch 174/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8945 - loss: 0.2312 - val_accuracy: 0.9377 - val_loss: 0.1761\n",
            "Epoch 175/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9197 - loss: 0.2174 - val_accuracy: 0.9309 - val_loss: 0.1957\n",
            "Epoch 176/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8750 - loss: 0.2533 - val_accuracy: 0.9298 - val_loss: 0.1991\n",
            "Epoch 177/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.9165 - loss: 0.2180 - val_accuracy: 0.9332 - val_loss: 0.1825\n",
            "Epoch 178/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9336 - loss: 0.2566 - val_accuracy: 0.9324 - val_loss: 0.1834\n",
            "Epoch 179/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.9225 - loss: 0.2088 - val_accuracy: 0.9308 - val_loss: 0.1826\n",
            "Epoch 180/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9336 - loss: 0.1685 - val_accuracy: 0.9308 - val_loss: 0.1824\n",
            "Epoch 181/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9190 - loss: 0.2183 - val_accuracy: 0.9367 - val_loss: 0.1760\n",
            "Epoch 182/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9180 - loss: 0.2102 - val_accuracy: 0.9374 - val_loss: 0.1759\n",
            "Epoch 183/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9228 - loss: 0.2071 - val_accuracy: 0.9352 - val_loss: 0.1800\n",
            "Epoch 184/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9336 - loss: 0.1773 - val_accuracy: 0.9350 - val_loss: 0.1815\n",
            "Epoch 185/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9195 - loss: 0.2190 - val_accuracy: 0.9315 - val_loss: 0.1861\n",
            "Epoch 186/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2100 - val_accuracy: 0.9310 - val_loss: 0.1864\n",
            "Epoch 187/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.9194 - loss: 0.2102 - val_accuracy: 0.9268 - val_loss: 0.2010\n",
            "Epoch 188/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9141 - loss: 0.2072 - val_accuracy: 0.9286 - val_loss: 0.1967\n",
            "Epoch 189/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 82ms/step - accuracy: 0.9230 - loss: 0.2093 - val_accuracy: 0.9357 - val_loss: 0.1791\n",
            "Epoch 190/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9141 - loss: 0.2625 - val_accuracy: 0.9356 - val_loss: 0.1798\n",
            "Epoch 191/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 86ms/step - accuracy: 0.9226 - loss: 0.2084 - val_accuracy: 0.9358 - val_loss: 0.1818\n",
            "Epoch 192/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9141 - loss: 0.2612 - val_accuracy: 0.9359 - val_loss: 0.1818\n",
            "Epoch 193/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 83ms/step - accuracy: 0.9207 - loss: 0.2131 - val_accuracy: 0.9389 - val_loss: 0.1711\n",
            "Epoch 194/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9062 - loss: 0.2765 - val_accuracy: 0.9387 - val_loss: 0.1712\n",
            "Epoch 195/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9215 - loss: 0.2119 - val_accuracy: 0.9366 - val_loss: 0.1770\n",
            "Epoch 196/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9219 - loss: 0.2308 - val_accuracy: 0.9360 - val_loss: 0.1783\n",
            "Epoch 197/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9213 - loss: 0.2110 - val_accuracy: 0.9373 - val_loss: 0.1754\n",
            "Epoch 198/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9219 - loss: 0.2105 - val_accuracy: 0.9367 - val_loss: 0.1758\n",
            "Epoch 199/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 83ms/step - accuracy: 0.9241 - loss: 0.2054 - val_accuracy: 0.9367 - val_loss: 0.1771\n",
            "Epoch 200/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9297 - loss: 0.2482 - val_accuracy: 0.9377 - val_loss: 0.1758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_trace(x,y,ylabel,color):\n",
        "  # trace = go.Scatter(x=x, y=y, name=ylabel, marker=dict(color=color), mode='markers+lines', text=x)\n",
        "  trace = go.Scatter(x=list(x), y=y, name=ylabel, marker=dict(color=color), mode='markers+lines', text=list(x))\n",
        "  return trace\n",
        "\n",
        "def plot_accuracy_and_loss(train_model):\n",
        "  hist = train_model.history\n",
        "  acc = hist['accuracy']\n",
        "  val_acc = hist['val_accuracy']\n",
        "  loss = hist['loss']\n",
        "  val_loss = hist['val_loss']\n",
        "  epochs = range(1,len(acc)+1)\n",
        "\n",
        "  trace_ta = create_trace(epochs,acc,'Training Accuracy','green')\n",
        "  trace_ts = create_trace(epochs,val_acc,'Validation Accuracy','red')\n",
        "  trace_tl = create_trace(epochs,loss,'Training Loss','blue')\n",
        "  trace_vl = create_trace(epochs,val_loss,'Validation Loss','magenta')\n",
        "\n",
        "  fig = subplots.make_subplots(rows=1,cols=2,subplot_titles=('Training and Validation Accuracy','Training and Validation Loss'))\n",
        "  fig.append_trace(trace_ta,1,1)\n",
        "  fig.append_trace(trace_ts,1,1)\n",
        "  fig.append_trace(trace_tl,1,2)\n",
        "  fig.append_trace(trace_vl,1,2)\n",
        "  fig['layout']['xaxis'].update(title='Epoch')\n",
        "  fig['layout']['xaxis2'].update(title='Epoch')\n",
        "  fig['layout']['yaxis'].update(title='Accuracy',range=[0,1])\n",
        "  fig['layout']['yaxis2'].update(title='Loss',range=[0,1])\n",
        "\n",
        "  plotly.offline.iplot(fig,filename='accuracy-loss')"
      ],
      "metadata": {
        "id": "5dGSpj8qKOBY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracy_and_loss(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "c5QdKMJMKPnc",
        "outputId": "fec5c526-f567-4b99-a7dd-76f2b3430638"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"54e0414d-79a5-4a29-a054-805aa1409824\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"54e0414d-79a5-4a29-a054-805aa1409824\")) {                    Plotly.newPlot(                        \"54e0414d-79a5-4a29-a054-805aa1409824\",                        [{\"marker\":{\"color\":\"green\"},\"mode\":\"markers+lines\",\"name\":\"Training Accuracy\",\"text\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\",\"151\",\"152\",\"153\",\"154\",\"155\",\"156\",\"157\",\"158\",\"159\",\"160\",\"161\",\"162\",\"163\",\"164\",\"165\",\"166\",\"167\",\"168\",\"169\",\"170\",\"171\",\"172\",\"173\",\"174\",\"175\",\"176\",\"177\",\"178\",\"179\",\"180\",\"181\",\"182\",\"183\",\"184\",\"185\",\"186\",\"187\",\"188\",\"189\",\"190\",\"191\",\"192\",\"193\",\"194\",\"195\",\"196\",\"197\",\"198\",\"199\",\"200\"],\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200],\"xaxis\":\"x\",\"y\":[0.6954172253608704,0.8515625,0.7837634086608887,0.80078125,0.8106358647346497,0.8515625,0.8293607831001282,0.84765625,0.8410062193870544,0.80859375,0.8493632674217224,0.83984375,0.8556258082389832,0.83984375,0.8601918816566467,0.87890625,0.8650510907173157,0.87890625,0.8675435781478882,0.85546875,0.8713346123695374,0.84765625,0.8755027055740356,0.87890625,0.877345860004425,0.89453125,0.8792518377304077,0.89453125,0.8810112476348877,0.875,0.8796079158782959,0.87890625,0.8829800486564636,0.89453125,0.8870643377304077,0.83984375,0.8898500204086304,0.91796875,0.8897871971130371,0.88671875,0.8906669020652771,0.8671875,0.8913371562957764,0.9140625,0.8936620354652405,0.91015625,0.8931593298912048,0.875,0.8927823305130005,0.9296875,0.894667387008667,0.88671875,0.8969294428825378,0.8828125,0.8996313810348511,0.90234375,0.8978091478347778,0.91796875,0.899861752986908,0.9140625,0.8987516760826111,0.9296875,0.9006158113479614,0.9375,0.9014536142349243,0.89453125,0.9005948305130005,0.91796875,0.9021657109260559,0.90234375,0.9029825925827026,0.921875,0.9046162962913513,0.8984375,0.9035271406173706,0.86328125,0.9036109447479248,0.859375,0.904511570930481,0.89453125,0.9045324921607971,0.90234375,0.9056007266044617,0.921875,0.9077370762825012,0.90625,0.9081978797912598,0.9140625,0.9071506261825562,0.9140625,0.9089519381523132,0.88671875,0.9098944664001465,0.921875,0.909412682056427,0.9453125,0.9085330367088318,0.890625,0.9110882878303528,0.90234375,0.9102085828781128,0.93359375,0.9105437397956848,0.921875,0.9119889140129089,0.875,0.9110882878303528,0.91796875,0.912910521030426,0.91015625,0.9110673666000366,0.93359375,0.9132456183433533,0.91796875,0.9124706983566284,0.9140625,0.9118423461914062,0.90625,0.9142091274261475,0.91015625,0.9139158725738525,0.91015625,0.9138949513435364,0.8984375,0.9142510294914246,0.875,0.9139368534088135,0.87109375,0.9138530492782593,0.91015625,0.9154658317565918,0.91796875,0.9136016964912415,0.91015625,0.9141672253608704,0.90625,0.9162408113479614,0.91796875,0.9159684777259827,0.9296875,0.9157171845436096,0.93359375,0.9153820276260376,0.91015625,0.9173718094825745,0.90234375,0.918712317943573,0.88671875,0.9174137115478516,0.8984375,0.9177488088607788,0.8984375,0.9185656905174255,0.90234375,0.916952908039093,0.9296875,0.9178535342216492,0.9375,0.9161360859870911,0.92578125,0.9210371971130371,0.91796875,0.9174975156784058,0.92578125,0.9171623587608337,0.9140625,0.9174975156784058,0.9296875,0.9192149639129639,0.93359375,0.9208486676216125,0.94140625,0.9205763936042786,0.89453125,0.9194663166999817,0.875,0.9178954362869263,0.93359375,0.9208068251609802,0.93359375,0.9203041195869446,0.91796875,0.9208905696868896,0.93359375,0.9192987680435181,0.9140625,0.9199061393737793,0.9140625,0.921875,0.9140625,0.9194663166999817,0.9140625,0.9212257266044617,0.90625,0.9220216274261475,0.921875,0.921330451965332,0.921875,0.9234249591827393,0.9296875],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\"},\"mode\":\"markers+lines\",\"name\":\"Validation Accuracy\",\"text\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\",\"151\",\"152\",\"153\",\"154\",\"155\",\"156\",\"157\",\"158\",\"159\",\"160\",\"161\",\"162\",\"163\",\"164\",\"165\",\"166\",\"167\",\"168\",\"169\",\"170\",\"171\",\"172\",\"173\",\"174\",\"175\",\"176\",\"177\",\"178\",\"179\",\"180\",\"181\",\"182\",\"183\",\"184\",\"185\",\"186\",\"187\",\"188\",\"189\",\"190\",\"191\",\"192\",\"193\",\"194\",\"195\",\"196\",\"197\",\"198\",\"199\",\"200\"],\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200],\"xaxis\":\"x\",\"y\":[0.1511666625738144,0.14216665923595428,0.46791666746139526,0.4663333296775818,0.7512500286102295,0.746916651725769,0.8339999914169312,0.8222500085830688,0.8899999856948853,0.887333333492279,0.8848333358764648,0.8861666917800903,0.8880000114440918,0.8893333077430725,0.8827499747276306,0.8811666369438171,0.903249979019165,0.906083345413208,0.8973333239555359,0.8989166617393494,0.9049166440963745,0.9038333296775818,0.9141666889190674,0.9139166474342346,0.9135833382606506,0.9141666889190674,0.9113333225250244,0.9128333330154419,0.9164999723434448,0.9165833592414856,0.9165833592414856,0.9170833230018616,0.9146666526794434,0.9154999852180481,0.9175000190734863,0.918916642665863,0.9105833172798157,0.9106666445732117,0.9135000109672546,0.9155833125114441,0.9178333282470703,0.9168333411216736,0.9198333621025085,0.9205833077430725,0.92166668176651,0.921500027179718,0.922166645526886,0.9234166741371155,0.9190833568572998,0.918583333492279,0.9247499704360962,0.9247499704360962,0.9234166741371155,0.9232500195503235,0.9169999957084656,0.9175000190734863,0.9258333444595337,0.9259999990463257,0.9262499809265137,0.9273333549499512,0.9256666898727417,0.9253333210945129,0.9242500066757202,0.9235000014305115,0.9227499961853027,0.9234166741371155,0.9259999990463257,0.9262499809265137,0.9263333082199097,0.9264166951179504,0.9255833625793457,0.925166666507721,0.9252499938011169,0.9259166717529297,0.9267500042915344,0.9289166927337646,0.9286666512489319,0.9285833239555359,0.9257500171661377,0.9261666536331177,0.9279999732971191,0.9290833473205566,0.9239166378974915,0.9230833053588867,0.9319166541099548,0.9311666488647461,0.9334999918937683,0.9332500100135803,0.9297500252723694,0.9314166903495789,0.9299166798591614,0.9290000200271606,0.9305833578109741,0.9301666617393494,0.9282500147819519,0.9276666641235352,0.9290000200271606,0.9297500252723694,0.9297500252723694,0.9295833110809326,0.934583306312561,0.9352499842643738,0.9242500066757202,0.9244999885559082,0.9224166870117188,0.922249972820282,0.9283333420753479,0.9276666641235352,0.9308333396911621,0.9309166669845581,0.9319999814033508,0.9325000047683716,0.9290000200271606,0.9285833239555359,0.9313333630561829,0.9296666383743286,0.9313333630561829,0.9321666955947876,0.9329166412353516,0.9326666593551636,0.924833357334137,0.9245833158493042,0.921833336353302,0.9243333339691162,0.9319999814033508,0.9324166774749756,0.9333333373069763,0.9338333606719971,0.9354166388511658,0.9335833191871643,0.9321666955947876,0.9337499737739563,0.9321666955947876,0.9325000047683716,0.9275000095367432,0.9264166951179504,0.9329166412353516,0.9327499866485596,0.9346666932106018,0.9348333477973938,0.9274166822433472,0.9292500019073486,0.9358333349227905,0.9353333115577698,0.9314166903495789,0.9316666722297668,0.9389166831970215,0.9382500052452087,0.9275833368301392,0.9277499914169312,0.9334999918937683,0.9330833554267883,0.9306666851043701,0.9314166903495789,0.9350833296775818,0.9349166750907898,0.9334999918937683,0.9329166412353516,0.9304999709129333,0.9301666617393494,0.9375,0.9367499947547913,0.9325000047683716,0.9327499866485596,0.934249997138977,0.9330833554267883,0.9364166855812073,0.9365000128746033,0.9381666779518127,0.9381666779518127,0.9316666722297668,0.9316666722297668,0.9369166493415833,0.937749981880188,0.9309166669845581,0.9297500252723694,0.9331666827201843,0.9324166774749756,0.9307500123977661,0.9308333396911621,0.9367499947547913,0.937416672706604,0.9352499842643738,0.9350000023841858,0.9315000176429749,0.9309999942779541,0.9267500042915344,0.9285833239555359,0.9356666803359985,0.9355833530426025,0.9358333349227905,0.9359166622161865,0.9389166831970215,0.9386666417121887,0.9365833401679993,0.9359999895095825,0.937250018119812,0.9367499947547913,0.9367499947547913,0.937666654586792],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\"},\"mode\":\"markers+lines\",\"name\":\"Training Loss\",\"text\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\",\"151\",\"152\",\"153\",\"154\",\"155\",\"156\",\"157\",\"158\",\"159\",\"160\",\"161\",\"162\",\"163\",\"164\",\"165\",\"166\",\"167\",\"168\",\"169\",\"170\",\"171\",\"172\",\"173\",\"174\",\"175\",\"176\",\"177\",\"178\",\"179\",\"180\",\"181\",\"182\",\"183\",\"184\",\"185\",\"186\",\"187\",\"188\",\"189\",\"190\",\"191\",\"192\",\"193\",\"194\",\"195\",\"196\",\"197\",\"198\",\"199\",\"200\"],\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200],\"xaxis\":\"x2\",\"y\":[0.8171738386154175,0.5298252701759338,0.5702284574508667,0.5053002238273621,0.497587651014328,0.4717130661010742,0.4545181691646576,0.3925938010215759,0.4221547245979309,0.48453807830810547,0.40485629439353943,0.39903485774993896,0.38731953501701355,0.40279996395111084,0.3748950660228729,0.34570416808128357,0.36367249488830566,0.29052823781967163,0.3563097417354584,0.39478641748428345,0.34647130966186523,0.40577495098114014,0.3372769057750702,0.32445695996284485,0.3287791311740875,0.3017127513885498,0.3249264657497406,0.3120439648628235,0.32038334012031555,0.3162044584751129,0.3204575777053833,0.2980697751045227,0.3132590651512146,0.24467448890209198,0.30296239256858826,0.41588184237480164,0.29595088958740234,0.31001216173171997,0.2993616759777069,0.3395211100578308,0.2928246557712555,0.34511250257492065,0.29026713967323303,0.24373546242713928,0.2854333519935608,0.2751375138759613,0.2867002785205841,0.33146682381629944,0.28749075531959534,0.21083664894104004,0.28394758701324463,0.3257209062576294,0.27661705017089844,0.34241053462028503,0.27308306097984314,0.2288511097431183,0.2765054702758789,0.25369060039520264,0.27158620953559875,0.24497590959072113,0.2681341767311096,0.2009173184633255,0.2679356336593628,0.1876867413520813,0.26655590534210205,0.3315718472003937,0.264891654253006,0.2354620397090912,0.2643989622592926,0.2523314952850342,0.25868886709213257,0.2101723849773407,0.2585411071777344,0.24449491500854492,0.2588828206062317,0.3331494927406311,0.2580333650112152,0.31130266189575195,0.25653550028800964,0.2801905870437622,0.2569248676300049,0.23805619776248932,0.2527368366718292,0.25365716218948364,0.24559126794338226,0.25841885805130005,0.24626724421977997,0.2313106656074524,0.24618935585021973,0.22856144607067108,0.24657534062862396,0.29418838024139404,0.24622271955013275,0.19229158759117126,0.24258267879486084,0.16375571489334106,0.2464246153831482,0.2593469023704529,0.24087859690189362,0.3094252645969391,0.24269258975982666,0.18147346377372742,0.23861050605773926,0.21548445522785187,0.23776449263095856,0.3010718524456024,0.23974664509296417,0.20130625367164612,0.2339203804731369,0.2693125605583191,0.23722141981124878,0.18127897381782532,0.23634421825408936,0.2267627716064453,0.23640522360801697,0.23378372192382812,0.236333429813385,0.2975327968597412,0.2295094132423401,0.2233630269765854,0.23230072855949402,0.22160182893276215,0.2301824688911438,0.3013298511505127,0.23107218742370605,0.32262367010116577,0.23074191808700562,0.32028043270111084,0.23083624243736267,0.22050347924232483,0.226775124669075,0.2316988855600357,0.22978799045085907,0.24214664101600647,0.22595830261707306,0.2381986826658249,0.22395841777324677,0.2468366026878357,0.22660966217517853,0.18563953042030334,0.2242809236049652,0.20724770426750183,0.22478249669075012,0.20403195917606354,0.2215672731399536,0.25819334387779236,0.22028228640556335,0.26445096731185913,0.22173187136650085,0.3252156376838684,0.22354784607887268,0.21962085366249084,0.21838484704494476,0.21712541580200195,0.22290699183940887,0.17343507707118988,0.21996289491653442,0.1553664207458496,0.21967634558677673,0.23904559016227722,0.21459631621837616,0.20637226104736328,0.22107923030853271,0.1864320933818817,0.22152268886566162,0.21721678972244263,0.2201533317565918,0.18756063282489777,0.2182682305574417,0.21043726801872253,0.21308359503746033,0.1811358630657196,0.21573659777641296,0.23124507069587708,0.21737797558307648,0.2533336579799652,0.21588237583637238,0.25664839148521423,0.21154017746448517,0.16849073767662048,0.21252447366714478,0.21020370721817017,0.21196039021015167,0.17729300260543823,0.2159067690372467,0.21000553667545319,0.21086585521697998,0.20720259845256805,0.2119123637676239,0.26246339082717896,0.21510423719882965,0.26122406125068665,0.21054492890834808,0.27654600143432617,0.21275168657302856,0.2308114469051361,0.20919010043144226,0.21047696471214294,0.20653030276298523,0.24823503196239471],\"yaxis\":\"y2\",\"type\":\"scatter\"},{\"marker\":{\"color\":\"magenta\"},\"mode\":\"markers+lines\",\"name\":\"Validation Loss\",\"text\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\",\"151\",\"152\",\"153\",\"154\",\"155\",\"156\",\"157\",\"158\",\"159\",\"160\",\"161\",\"162\",\"163\",\"164\",\"165\",\"166\",\"167\",\"168\",\"169\",\"170\",\"171\",\"172\",\"173\",\"174\",\"175\",\"176\",\"177\",\"178\",\"179\",\"180\",\"181\",\"182\",\"183\",\"184\",\"185\",\"186\",\"187\",\"188\",\"189\",\"190\",\"191\",\"192\",\"193\",\"194\",\"195\",\"196\",\"197\",\"198\",\"199\",\"200\"],\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200],\"xaxis\":\"x2\",\"y\":[2.8556389808654785,2.866471767425537,1.9657537937164307,1.942867636680603,0.6660523414611816,0.6823211908340454,0.45072299242019653,0.4796525537967682,0.29756930470466614,0.3050564229488373,0.30333244800567627,0.29845526814460754,0.3026139438152313,0.29611554741859436,0.31770211458206177,0.32480567693710327,0.2611915171146393,0.25409191846847534,0.2673223614692688,0.26440325379371643,0.2465379387140274,0.24931976199150085,0.23413297533988953,0.2360742837190628,0.23349997401237488,0.234756737947464,0.2377798706293106,0.23387882113456726,0.228155255317688,0.2274046242237091,0.22526590526103973,0.22377002239227295,0.2288876175880432,0.22967617213726044,0.22700318694114685,0.22302228212356567,0.2410583347082138,0.23819436132907867,0.23255625367164612,0.22565118968486786,0.22097712755203247,0.22294700145721436,0.21881210803985596,0.21838364005088806,0.20872050523757935,0.2094230353832245,0.20766989886760712,0.20552319288253784,0.21495646238327026,0.21660734713077545,0.20535142719745636,0.20508970320224762,0.20578274130821228,0.20673799514770508,0.2190687656402588,0.21665436029434204,0.20136183500289917,0.20205475389957428,0.19892996549606323,0.2000570297241211,0.20186971127986908,0.20170141756534576,0.20985056459903717,0.2121059149503708,0.2045518159866333,0.20367099344730377,0.2074914574623108,0.20683857798576355,0.1974240243434906,0.19765762984752655,0.19895780086517334,0.1985865831375122,0.20100285112857819,0.20175319910049438,0.1959010809659958,0.19215509295463562,0.19391672313213348,0.19478289783000946,0.1989150047302246,0.1981704980134964,0.1936550736427307,0.19096004962921143,0.20143166184425354,0.20206862688064575,0.18631672859191895,0.1867421716451645,0.18444591760635376,0.18528437614440918,0.1917746514081955,0.18928483128547668,0.1913323998451233,0.19129598140716553,0.18696850538253784,0.1867794394493103,0.19296611845493317,0.1935356706380844,0.19116702675819397,0.19007834792137146,0.1917230635881424,0.192247211933136,0.18391279876232147,0.18344591557979584,0.20673415064811707,0.20641249418258667,0.20150265097618103,0.20240144431591034,0.19498693943023682,0.19515323638916016,0.1920941323041916,0.19280612468719482,0.18742096424102783,0.1875418871641159,0.1927020400762558,0.1931786835193634,0.18937928974628448,0.19060219824314117,0.18381206691265106,0.18190503120422363,0.1837633103132248,0.18412898480892181,0.206625834107399,0.2082105129957199,0.2097286731004715,0.20350061357021332,0.1848207265138626,0.18430955708026886,0.18253882229328156,0.18241451680660248,0.1778373271226883,0.1802821308374405,0.18198303878307343,0.18031184375286102,0.18232832849025726,0.18286484479904175,0.19494272768497467,0.1977139711380005,0.1829034686088562,0.18408967554569244,0.17733384668827057,0.17751117050647736,0.1969335526227951,0.19573412835597992,0.17746691405773163,0.17963814735412598,0.18846167623996735,0.18824315071105957,0.17024560272693634,0.1721358299255371,0.1977667212486267,0.19682817161083221,0.18050624430179596,0.1801980435848236,0.18373224139213562,0.18311817944049835,0.18021070957183838,0.18018391728401184,0.18123175203800201,0.18291443586349487,0.18907879292964935,0.18891099095344543,0.17477256059646606,0.17476001381874084,0.18406951427459717,0.18449556827545166,0.18234938383102417,0.18583837151527405,0.17854803800582886,0.1776081919670105,0.17299073934555054,0.17367616295814514,0.1864137500524521,0.18571411073207855,0.17700642347335815,0.17611688375473022,0.19570250809192657,0.19913342595100403,0.18245288729667664,0.18340948224067688,0.1826249659061432,0.18236270546913147,0.1760164201259613,0.17591767013072968,0.1799534261226654,0.1814747154712677,0.18614830076694489,0.1863536536693573,0.20104405283927917,0.19666628539562225,0.1791037619113922,0.17975756525993347,0.1818264126777649,0.1817903220653534,0.17107604444026947,0.1711989790201187,0.17700399458408356,0.17825959622859955,0.17542316019535065,0.17580880224704742,0.17712540924549103,0.17578737437725067],\"yaxis\":\"y2\",\"type\":\"scatter\"}],                        {\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Training and Validation Accuracy\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Training and Validation Loss\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"range\":[0,1],\"title\":{\"text\":\"Accuracy\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"range\":[0,1],\"title\":{\"text\":\"Loss\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('54e0414d-79a5-4a29-a054-805aa1409824');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(test_data,y_test,verbose=0)\n",
        "print('Test loss:',score[0])\n",
        "print('Test accuracy:',score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlT9LNhGKRJO",
        "outputId": "3ce17467-0126-411f-d955-2bc62095b837"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.18564391136169434\n",
            "Test accuracy: 0.9330999851226807\n"
          ]
        }
      ]
    }
  ]
}