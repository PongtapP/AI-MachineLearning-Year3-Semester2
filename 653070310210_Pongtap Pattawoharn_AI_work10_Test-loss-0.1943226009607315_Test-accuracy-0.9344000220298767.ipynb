{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d20AgNdoJ3zm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "Adam = tf.keras.optimizers.Adam\n",
        "to_categorical = tf.keras.utils.to_categorical\n",
        "ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "load_img = tf.keras.preprocessing.image.load_img\n",
        "img_to_array = tf.keras.preprocessing.image.img_to_array\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "from plotly import subplots\n",
        "import plotly\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_ROWS = 28\n",
        "IMG_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "VAL_SIZE = 0.2\n",
        "RANDOM_STATE = 99\n",
        "BATCH_SIZE = 256"
      ],
      "metadata": {
        "id": "ETbhDUKkJ59h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data,y),(test_data,y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(\"Fashion MNIST train - rows:\",train_data.shape[0],\" columns:\",train_data.shape[1],\" rows:\",train_data.shape[2])\n",
        "print(\"Fashion MNIST test - rows:\",test_data.shape[0],\" columns:\",test_data.shape[1],\" rows:\",train_data.shape[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUxT-MRjJ77C",
        "outputId": "2e26e3fd-42ce-4c17-d556-b0946cabb893"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fashion MNIST train - rows: 60000  columns: 28  rows: 28\n",
            "Fashion MNIST test - rows: 10000  columns: 28  rows: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape, test_data.shape)\n",
        "\n",
        "train_data = train_data.reshape((train_data.shape[0], 28, 28, 1))\n",
        "test_data = test_data.reshape((test_data.shape[0], 28, 28, 1))\n",
        "\n",
        "print(train_data.shape, test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c9qwhfdKB0M",
        "outputId": "dd4e4fdb-18ca-4941-b7f0-b0e3190649ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (10000, 28, 28)\n",
            "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data/255.0\n",
        "test_data = test_data/255.0"
      ],
      "metadata": {
        "id": "LWBBRrUsKDDb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "uMIVUUpwKEoq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(train_data, y, test_size=VAL_SIZE, random_state=RANDOM_STATE)\n",
        "\n",
        "x_train.shape,x_val.shape,y_train.shape,y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-g0mNJ3KJqh",
        "outputId": "3627ea43-0746-4426-960b-6048a142884c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 28, 28, 1), (12000, 28, 28, 1), (48000, 10), (12000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,  # เพิ่ม rotation\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1  # เพิ่ม shear\n",
        ")\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "x32__KxoKSPF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# 1. CNN LAYER\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='Same', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.25))  # ลด Dropout\n",
        "\n",
        "# 2. CNN LAYER\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='Same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "# 3. CNN LAYER\n",
        "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='Same'))  # เพิ่ม filters\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "# 4. CNN LAYER\n",
        "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='Same'))  # เพิ่ม filters\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "# Fully Connected Layer\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "# Output Layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "wRhL30JCKZEq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ใช้ Adam พร้อม learning rate 0.0005\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "id": "6bIzknzgKaMF",
        "outputId": "89d9abbe-c3a0-4d82-96b4-aa7557133c3f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m147,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6272\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │       \u001b[38;5;34m1,605,888\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,570\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,888</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,870,026\u001b[0m (7.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,870,026</span> (7.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,868,746\u001b[0m (7.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,868,746</span> (7.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NO_EPOCH = 200\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
        "                    shuffle=True, epochs=NO_EPOCH, verbose=1,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    steps_per_epoch=x_train.shape[0] // BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7C20Y1XKb7k",
        "outputId": "4fb7d96f-b165-4a27-9e8a-60ba51959d96"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 131ms/step - accuracy: 0.6235 - loss: 1.0433 - val_accuracy: 0.1521 - val_loss: 3.4411\n",
            "Epoch 2/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7461 - loss: 0.6449 - val_accuracy: 0.1268 - val_loss: 3.4548\n",
            "Epoch 3/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.7753 - loss: 0.5864 - val_accuracy: 0.3049 - val_loss: 2.3042\n",
            "Epoch 4/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8594 - loss: 0.3896 - val_accuracy: 0.2984 - val_loss: 2.3307\n",
            "Epoch 5/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 83ms/step - accuracy: 0.8098 - loss: 0.5010 - val_accuracy: 0.6522 - val_loss: 1.0434\n",
            "Epoch 6/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8359 - loss: 0.4333 - val_accuracy: 0.6488 - val_loss: 1.0634\n",
            "Epoch 7/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 0.8228 - loss: 0.4692 - val_accuracy: 0.8637 - val_loss: 0.3604\n",
            "Epoch 8/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8320 - loss: 0.4630 - val_accuracy: 0.8504 - val_loss: 0.3968\n",
            "Epoch 9/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 83ms/step - accuracy: 0.8399 - loss: 0.4243 - val_accuracy: 0.8480 - val_loss: 0.4064\n",
            "Epoch 10/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8711 - loss: 0.3724 - val_accuracy: 0.8544 - val_loss: 0.3904\n",
            "Epoch 11/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 83ms/step - accuracy: 0.8494 - loss: 0.3994 - val_accuracy: 0.8924 - val_loss: 0.2872\n",
            "Epoch 12/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8516 - loss: 0.3936 - val_accuracy: 0.8983 - val_loss: 0.2772\n",
            "Epoch 13/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.8594 - loss: 0.3753 - val_accuracy: 0.8867 - val_loss: 0.3071\n",
            "Epoch 14/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8594 - loss: 0.3934 - val_accuracy: 0.8931 - val_loss: 0.2882\n",
            "Epoch 15/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 88ms/step - accuracy: 0.8660 - loss: 0.3598 - val_accuracy: 0.8952 - val_loss: 0.2844\n",
            "Epoch 16/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8789 - loss: 0.3644 - val_accuracy: 0.8928 - val_loss: 0.2901\n",
            "Epoch 17/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.8706 - loss: 0.3469 - val_accuracy: 0.9042 - val_loss: 0.2521\n",
            "Epoch 18/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9102 - loss: 0.2700 - val_accuracy: 0.9058 - val_loss: 0.2499\n",
            "Epoch 19/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 84ms/step - accuracy: 0.8745 - loss: 0.3336 - val_accuracy: 0.8961 - val_loss: 0.2788\n",
            "Epoch 20/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8867 - loss: 0.3408 - val_accuracy: 0.8940 - val_loss: 0.2855\n",
            "Epoch 21/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.8772 - loss: 0.3289 - val_accuracy: 0.9018 - val_loss: 0.2618\n",
            "Epoch 22/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8906 - loss: 0.2744 - val_accuracy: 0.8998 - val_loss: 0.2667\n",
            "Epoch 23/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 84ms/step - accuracy: 0.8809 - loss: 0.3223 - val_accuracy: 0.9077 - val_loss: 0.2469\n",
            "Epoch 24/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8984 - loss: 0.2950 - val_accuracy: 0.9073 - val_loss: 0.2481\n",
            "Epoch 25/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 0.8850 - loss: 0.3110 - val_accuracy: 0.9092 - val_loss: 0.2426\n",
            "Epoch 26/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8945 - loss: 0.3091 - val_accuracy: 0.9103 - val_loss: 0.2405\n",
            "Epoch 27/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 82ms/step - accuracy: 0.8827 - loss: 0.3124 - val_accuracy: 0.9007 - val_loss: 0.2653\n",
            "Epoch 28/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9180 - loss: 0.2777 - val_accuracy: 0.8988 - val_loss: 0.2708\n",
            "Epoch 29/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 86ms/step - accuracy: 0.8894 - loss: 0.2984 - val_accuracy: 0.9145 - val_loss: 0.2312\n",
            "Epoch 30/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8789 - loss: 0.2746 - val_accuracy: 0.9149 - val_loss: 0.2325\n",
            "Epoch 31/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.8890 - loss: 0.2983 - val_accuracy: 0.9062 - val_loss: 0.2523\n",
            "Epoch 32/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8789 - loss: 0.3237 - val_accuracy: 0.9069 - val_loss: 0.2501\n",
            "Epoch 33/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.8915 - loss: 0.2873 - val_accuracy: 0.9207 - val_loss: 0.2174\n",
            "Epoch 34/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9023 - loss: 0.2591 - val_accuracy: 0.9191 - val_loss: 0.2182\n",
            "Epoch 35/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.8938 - loss: 0.2843 - val_accuracy: 0.9165 - val_loss: 0.2253\n",
            "Epoch 36/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8906 - loss: 0.3339 - val_accuracy: 0.9185 - val_loss: 0.2221\n",
            "Epoch 37/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.8958 - loss: 0.2795 - val_accuracy: 0.9057 - val_loss: 0.2539\n",
            "Epoch 38/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8750 - loss: 0.2885 - val_accuracy: 0.9078 - val_loss: 0.2501\n",
            "Epoch 39/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.8982 - loss: 0.2771 - val_accuracy: 0.9072 - val_loss: 0.2586\n",
            "Epoch 40/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9141 - loss: 0.2173 - val_accuracy: 0.9082 - val_loss: 0.2586\n",
            "Epoch 41/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.9006 - loss: 0.2674 - val_accuracy: 0.9149 - val_loss: 0.2328\n",
            "Epoch 42/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8984 - loss: 0.2913 - val_accuracy: 0.9162 - val_loss: 0.2305\n",
            "Epoch 43/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.8995 - loss: 0.2679 - val_accuracy: 0.9071 - val_loss: 0.2487\n",
            "Epoch 44/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8945 - loss: 0.2373 - val_accuracy: 0.9099 - val_loss: 0.2418\n",
            "Epoch 45/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 0.9007 - loss: 0.2661 - val_accuracy: 0.9093 - val_loss: 0.2411\n",
            "Epoch 46/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8828 - loss: 0.3728 - val_accuracy: 0.9118 - val_loss: 0.2366\n",
            "Epoch 47/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9010 - loss: 0.2626 - val_accuracy: 0.9258 - val_loss: 0.2002\n",
            "Epoch 48/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8984 - loss: 0.2921 - val_accuracy: 0.9252 - val_loss: 0.2004\n",
            "Epoch 49/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 0.9023 - loss: 0.2638 - val_accuracy: 0.9121 - val_loss: 0.2362\n",
            "Epoch 50/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.2140 - val_accuracy: 0.9116 - val_loss: 0.2366\n",
            "Epoch 51/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.9041 - loss: 0.2583 - val_accuracy: 0.9231 - val_loss: 0.2100\n",
            "Epoch 52/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.2296 - val_accuracy: 0.9236 - val_loss: 0.2085\n",
            "Epoch 53/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 85ms/step - accuracy: 0.9062 - loss: 0.2510 - val_accuracy: 0.9239 - val_loss: 0.2056\n",
            "Epoch 54/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9102 - loss: 0.3007 - val_accuracy: 0.9241 - val_loss: 0.2045\n",
            "Epoch 55/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.9099 - loss: 0.2463 - val_accuracy: 0.9214 - val_loss: 0.2107\n",
            "Epoch 56/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9141 - loss: 0.2258 - val_accuracy: 0.9209 - val_loss: 0.2111\n",
            "Epoch 57/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 84ms/step - accuracy: 0.9089 - loss: 0.2470 - val_accuracy: 0.9178 - val_loss: 0.2236\n",
            "Epoch 58/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9180 - loss: 0.2153 - val_accuracy: 0.9174 - val_loss: 0.2254\n",
            "Epoch 59/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 83ms/step - accuracy: 0.9094 - loss: 0.2480 - val_accuracy: 0.9291 - val_loss: 0.1978\n",
            "Epoch 60/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8945 - loss: 0.3074 - val_accuracy: 0.9293 - val_loss: 0.1969\n",
            "Epoch 61/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 87ms/step - accuracy: 0.9115 - loss: 0.2420 - val_accuracy: 0.9215 - val_loss: 0.2117\n",
            "Epoch 62/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9102 - loss: 0.2243 - val_accuracy: 0.9239 - val_loss: 0.2086\n",
            "Epoch 63/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9106 - loss: 0.2406 - val_accuracy: 0.9169 - val_loss: 0.2317\n",
            "Epoch 64/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9062 - loss: 0.2457 - val_accuracy: 0.9163 - val_loss: 0.2316\n",
            "Epoch 65/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 83ms/step - accuracy: 0.9134 - loss: 0.2361 - val_accuracy: 0.9262 - val_loss: 0.2020\n",
            "Epoch 66/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9023 - loss: 0.2497 - val_accuracy: 0.9263 - val_loss: 0.2029\n",
            "Epoch 67/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 87ms/step - accuracy: 0.9160 - loss: 0.2305 - val_accuracy: 0.9173 - val_loss: 0.2278\n",
            "Epoch 68/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9258 - loss: 0.2411 - val_accuracy: 0.9178 - val_loss: 0.2279\n",
            "Epoch 69/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9155 - loss: 0.2302 - val_accuracy: 0.9170 - val_loss: 0.2353\n",
            "Epoch 70/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.2363 - val_accuracy: 0.9183 - val_loss: 0.2297\n",
            "Epoch 71/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.9115 - loss: 0.2373 - val_accuracy: 0.9173 - val_loss: 0.2251\n",
            "Epoch 72/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9453 - loss: 0.1488 - val_accuracy: 0.9195 - val_loss: 0.2200\n",
            "Epoch 73/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 83ms/step - accuracy: 0.9139 - loss: 0.2306 - val_accuracy: 0.9161 - val_loss: 0.2295\n",
            "Epoch 74/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9453 - loss: 0.1701 - val_accuracy: 0.9160 - val_loss: 0.2324\n",
            "Epoch 75/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 86ms/step - accuracy: 0.9165 - loss: 0.2267 - val_accuracy: 0.9224 - val_loss: 0.2168\n",
            "Epoch 76/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9219 - loss: 0.2284 - val_accuracy: 0.9212 - val_loss: 0.2180\n",
            "Epoch 77/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.9206 - loss: 0.2183 - val_accuracy: 0.9269 - val_loss: 0.1951\n",
            "Epoch 78/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8984 - loss: 0.3350 - val_accuracy: 0.9258 - val_loss: 0.1979\n",
            "Epoch 79/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 93ms/step - accuracy: 0.9191 - loss: 0.2164 - val_accuracy: 0.9286 - val_loss: 0.1979\n",
            "Epoch 80/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9141 - loss: 0.1954 - val_accuracy: 0.9287 - val_loss: 0.1971\n",
            "Epoch 81/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.9184 - loss: 0.2224 - val_accuracy: 0.9012 - val_loss: 0.2795\n",
            "Epoch 82/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9180 - loss: 0.2261 - val_accuracy: 0.8991 - val_loss: 0.2876\n",
            "Epoch 83/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 85ms/step - accuracy: 0.9187 - loss: 0.2168 - val_accuracy: 0.9301 - val_loss: 0.1935\n",
            "Epoch 84/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9102 - loss: 0.2385 - val_accuracy: 0.9302 - val_loss: 0.1921\n",
            "Epoch 85/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9176 - loss: 0.2181 - val_accuracy: 0.9220 - val_loss: 0.2161\n",
            "Epoch 86/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9336 - loss: 0.1938 - val_accuracy: 0.9208 - val_loss: 0.2195\n",
            "Epoch 87/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9209 - loss: 0.2144 - val_accuracy: 0.9221 - val_loss: 0.2124\n",
            "Epoch 88/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9453 - loss: 0.1605 - val_accuracy: 0.9218 - val_loss: 0.2122\n",
            "Epoch 89/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 87ms/step - accuracy: 0.9187 - loss: 0.2161 - val_accuracy: 0.9211 - val_loss: 0.2173\n",
            "Epoch 90/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9180 - loss: 0.2372 - val_accuracy: 0.9228 - val_loss: 0.2150\n",
            "Epoch 91/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 85ms/step - accuracy: 0.9220 - loss: 0.2118 - val_accuracy: 0.9223 - val_loss: 0.2131\n",
            "Epoch 92/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9062 - loss: 0.1958 - val_accuracy: 0.9209 - val_loss: 0.2169\n",
            "Epoch 93/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 88ms/step - accuracy: 0.9210 - loss: 0.2128 - val_accuracy: 0.9113 - val_loss: 0.2553\n",
            "Epoch 94/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9180 - loss: 0.2296 - val_accuracy: 0.9107 - val_loss: 0.2544\n",
            "Epoch 95/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 85ms/step - accuracy: 0.9221 - loss: 0.2090 - val_accuracy: 0.9204 - val_loss: 0.2255\n",
            "Epoch 96/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9258 - loss: 0.2021 - val_accuracy: 0.9191 - val_loss: 0.2289\n",
            "Epoch 97/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 86ms/step - accuracy: 0.9234 - loss: 0.2061 - val_accuracy: 0.9178 - val_loss: 0.2298\n",
            "Epoch 98/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9023 - loss: 0.2477 - val_accuracy: 0.9178 - val_loss: 0.2298\n",
            "Epoch 99/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 89ms/step - accuracy: 0.9234 - loss: 0.2082 - val_accuracy: 0.9195 - val_loss: 0.2180\n",
            "Epoch 100/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9180 - loss: 0.2054 - val_accuracy: 0.9206 - val_loss: 0.2181\n",
            "Epoch 101/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.9237 - loss: 0.2049 - val_accuracy: 0.9177 - val_loss: 0.2290\n",
            "Epoch 102/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8906 - loss: 0.3123 - val_accuracy: 0.9174 - val_loss: 0.2299\n",
            "Epoch 103/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9245 - loss: 0.2027 - val_accuracy: 0.9183 - val_loss: 0.2294\n",
            "Epoch 104/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8906 - loss: 0.2535 - val_accuracy: 0.9184 - val_loss: 0.2304\n",
            "Epoch 105/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.9264 - loss: 0.1970 - val_accuracy: 0.9180 - val_loss: 0.2381\n",
            "Epoch 106/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9062 - loss: 0.2228 - val_accuracy: 0.9183 - val_loss: 0.2360\n",
            "Epoch 107/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 0.9221 - loss: 0.2060 - val_accuracy: 0.9220 - val_loss: 0.2138\n",
            "Epoch 108/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9258 - loss: 0.1750 - val_accuracy: 0.9237 - val_loss: 0.2131\n",
            "Epoch 109/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.9253 - loss: 0.2008 - val_accuracy: 0.9283 - val_loss: 0.2046\n",
            "Epoch 110/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9297 - loss: 0.2436 - val_accuracy: 0.9279 - val_loss: 0.2027\n",
            "Epoch 111/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9256 - loss: 0.1989 - val_accuracy: 0.9262 - val_loss: 0.2113\n",
            "Epoch 112/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9062 - loss: 0.2415 - val_accuracy: 0.9254 - val_loss: 0.2110\n",
            "Epoch 113/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 84ms/step - accuracy: 0.9297 - loss: 0.1910 - val_accuracy: 0.9258 - val_loss: 0.2040\n",
            "Epoch 114/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9258 - loss: 0.1875 - val_accuracy: 0.9252 - val_loss: 0.2071\n",
            "Epoch 115/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 0.9287 - loss: 0.1956 - val_accuracy: 0.9258 - val_loss: 0.2029\n",
            "Epoch 116/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9609 - loss: 0.1267 - val_accuracy: 0.9254 - val_loss: 0.2043\n",
            "Epoch 117/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 83ms/step - accuracy: 0.9315 - loss: 0.1858 - val_accuracy: 0.9243 - val_loss: 0.2139\n",
            "Epoch 118/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9141 - loss: 0.2163 - val_accuracy: 0.9235 - val_loss: 0.2146\n",
            "Epoch 119/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 88ms/step - accuracy: 0.9295 - loss: 0.1925 - val_accuracy: 0.9337 - val_loss: 0.1885\n",
            "Epoch 120/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9414 - loss: 0.1867 - val_accuracy: 0.9330 - val_loss: 0.1921\n",
            "Epoch 121/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9299 - loss: 0.1900 - val_accuracy: 0.9117 - val_loss: 0.2536\n",
            "Epoch 122/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9453 - loss: 0.1930 - val_accuracy: 0.9129 - val_loss: 0.2503\n",
            "Epoch 123/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9312 - loss: 0.1895 - val_accuracy: 0.9193 - val_loss: 0.2268\n",
            "Epoch 124/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.1996 - val_accuracy: 0.9193 - val_loss: 0.2260\n",
            "Epoch 125/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 85ms/step - accuracy: 0.9304 - loss: 0.1872 - val_accuracy: 0.9127 - val_loss: 0.2413\n",
            "Epoch 126/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9297 - loss: 0.1974 - val_accuracy: 0.9124 - val_loss: 0.2430\n",
            "Epoch 127/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.9323 - loss: 0.1868 - val_accuracy: 0.9158 - val_loss: 0.2473\n",
            "Epoch 128/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9414 - loss: 0.1335 - val_accuracy: 0.9154 - val_loss: 0.2487\n",
            "Epoch 129/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 86ms/step - accuracy: 0.9338 - loss: 0.1799 - val_accuracy: 0.9285 - val_loss: 0.2071\n",
            "Epoch 130/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8984 - loss: 0.2666 - val_accuracy: 0.9274 - val_loss: 0.2107\n",
            "Epoch 131/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9312 - loss: 0.1822 - val_accuracy: 0.9256 - val_loss: 0.2110\n",
            "Epoch 132/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9297 - loss: 0.1712 - val_accuracy: 0.9273 - val_loss: 0.2071\n",
            "Epoch 133/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 0.9334 - loss: 0.1830 - val_accuracy: 0.9287 - val_loss: 0.2032\n",
            "Epoch 134/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.1831 - val_accuracy: 0.9284 - val_loss: 0.2027\n",
            "Epoch 135/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9306 - loss: 0.1864 - val_accuracy: 0.9232 - val_loss: 0.2190\n",
            "Epoch 136/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.2050 - val_accuracy: 0.9235 - val_loss: 0.2196\n",
            "Epoch 137/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9307 - loss: 0.1852 - val_accuracy: 0.9197 - val_loss: 0.2229\n",
            "Epoch 138/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9141 - loss: 0.1868 - val_accuracy: 0.9207 - val_loss: 0.2192\n",
            "Epoch 139/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.9309 - loss: 0.1842 - val_accuracy: 0.9277 - val_loss: 0.2078\n",
            "Epoch 140/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9609 - loss: 0.1489 - val_accuracy: 0.9277 - val_loss: 0.2042\n",
            "Epoch 141/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 0.9330 - loss: 0.1782 - val_accuracy: 0.9316 - val_loss: 0.1908\n",
            "Epoch 142/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9297 - loss: 0.1792 - val_accuracy: 0.9327 - val_loss: 0.1887\n",
            "Epoch 143/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.9323 - loss: 0.1800 - val_accuracy: 0.9255 - val_loss: 0.2117\n",
            "Epoch 144/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9375 - loss: 0.1576 - val_accuracy: 0.9250 - val_loss: 0.2148\n",
            "Epoch 145/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 85ms/step - accuracy: 0.9344 - loss: 0.1768 - val_accuracy: 0.9254 - val_loss: 0.2075\n",
            "Epoch 146/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9180 - loss: 0.2113 - val_accuracy: 0.9258 - val_loss: 0.2073\n",
            "Epoch 147/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 95ms/step - accuracy: 0.9312 - loss: 0.1833 - val_accuracy: 0.9273 - val_loss: 0.2051\n",
            "Epoch 148/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.1636 - val_accuracy: 0.9279 - val_loss: 0.2056\n",
            "Epoch 149/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9346 - loss: 0.1738 - val_accuracy: 0.9224 - val_loss: 0.2223\n",
            "Epoch 150/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9141 - loss: 0.2099 - val_accuracy: 0.9235 - val_loss: 0.2201\n",
            "Epoch 151/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 85ms/step - accuracy: 0.9356 - loss: 0.1741 - val_accuracy: 0.9317 - val_loss: 0.1939\n",
            "Epoch 152/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9375 - loss: 0.1561 - val_accuracy: 0.9317 - val_loss: 0.1946\n",
            "Epoch 153/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.9335 - loss: 0.1775 - val_accuracy: 0.9370 - val_loss: 0.1789\n",
            "Epoch 154/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9102 - loss: 0.2368 - val_accuracy: 0.9373 - val_loss: 0.1782\n",
            "Epoch 155/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.9318 - loss: 0.1806 - val_accuracy: 0.9252 - val_loss: 0.2071\n",
            "Epoch 156/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9531 - loss: 0.1351 - val_accuracy: 0.9256 - val_loss: 0.2059\n",
            "Epoch 157/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9359 - loss: 0.1706 - val_accuracy: 0.9310 - val_loss: 0.1894\n",
            "Epoch 158/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.1793 - val_accuracy: 0.9302 - val_loss: 0.1897\n",
            "Epoch 159/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 88ms/step - accuracy: 0.9373 - loss: 0.1715 - val_accuracy: 0.9239 - val_loss: 0.2131\n",
            "Epoch 160/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9453 - loss: 0.1710 - val_accuracy: 0.9248 - val_loss: 0.2107\n",
            "Epoch 161/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 86ms/step - accuracy: 0.9354 - loss: 0.1728 - val_accuracy: 0.9327 - val_loss: 0.1910\n",
            "Epoch 162/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9492 - loss: 0.1477 - val_accuracy: 0.9320 - val_loss: 0.1916\n",
            "Epoch 163/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9351 - loss: 0.1694 - val_accuracy: 0.9323 - val_loss: 0.1913\n",
            "Epoch 164/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9180 - loss: 0.2167 - val_accuracy: 0.9333 - val_loss: 0.1914\n",
            "Epoch 165/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9380 - loss: 0.1693 - val_accuracy: 0.9269 - val_loss: 0.2080\n",
            "Epoch 166/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9453 - loss: 0.1376 - val_accuracy: 0.9265 - val_loss: 0.2080\n",
            "Epoch 167/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9351 - loss: 0.1727 - val_accuracy: 0.9221 - val_loss: 0.2261\n",
            "Epoch 168/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9180 - loss: 0.2390 - val_accuracy: 0.9215 - val_loss: 0.2286\n",
            "Epoch 169/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 0.9366 - loss: 0.1710 - val_accuracy: 0.9353 - val_loss: 0.1847\n",
            "Epoch 170/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.1491 - val_accuracy: 0.9353 - val_loss: 0.1845\n",
            "Epoch 171/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 85ms/step - accuracy: 0.9378 - loss: 0.1665 - val_accuracy: 0.9204 - val_loss: 0.2271\n",
            "Epoch 172/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9297 - loss: 0.1771 - val_accuracy: 0.9205 - val_loss: 0.2291\n",
            "Epoch 173/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 85ms/step - accuracy: 0.9383 - loss: 0.1708 - val_accuracy: 0.9324 - val_loss: 0.1916\n",
            "Epoch 174/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9336 - loss: 0.1569 - val_accuracy: 0.9342 - val_loss: 0.1885\n",
            "Epoch 175/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.9374 - loss: 0.1699 - val_accuracy: 0.9279 - val_loss: 0.2094\n",
            "Epoch 176/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8984 - loss: 0.2324 - val_accuracy: 0.9284 - val_loss: 0.2097\n",
            "Epoch 177/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 85ms/step - accuracy: 0.9398 - loss: 0.1646 - val_accuracy: 0.9272 - val_loss: 0.2143\n",
            "Epoch 178/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9258 - loss: 0.1691 - val_accuracy: 0.9260 - val_loss: 0.2174\n",
            "Epoch 179/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 85ms/step - accuracy: 0.9412 - loss: 0.1600 - val_accuracy: 0.9304 - val_loss: 0.1999\n",
            "Epoch 180/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9297 - loss: 0.1916 - val_accuracy: 0.9290 - val_loss: 0.2039\n",
            "Epoch 181/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.9418 - loss: 0.1635 - val_accuracy: 0.9317 - val_loss: 0.1956\n",
            "Epoch 182/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9336 - loss: 0.1809 - val_accuracy: 0.9303 - val_loss: 0.1987\n",
            "Epoch 183/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.9400 - loss: 0.1635 - val_accuracy: 0.9334 - val_loss: 0.1918\n",
            "Epoch 184/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9531 - loss: 0.1771 - val_accuracy: 0.9330 - val_loss: 0.1916\n",
            "Epoch 185/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 85ms/step - accuracy: 0.9395 - loss: 0.1596 - val_accuracy: 0.9228 - val_loss: 0.2218\n",
            "Epoch 186/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9453 - loss: 0.1644 - val_accuracy: 0.9222 - val_loss: 0.2262\n",
            "Epoch 187/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 88ms/step - accuracy: 0.9396 - loss: 0.1618 - val_accuracy: 0.9293 - val_loss: 0.2095\n",
            "Epoch 188/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9492 - loss: 0.1197 - val_accuracy: 0.9293 - val_loss: 0.2116\n",
            "Epoch 189/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 85ms/step - accuracy: 0.9388 - loss: 0.1609 - val_accuracy: 0.9323 - val_loss: 0.1932\n",
            "Epoch 190/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9688 - loss: 0.0738 - val_accuracy: 0.9337 - val_loss: 0.1922\n",
            "Epoch 191/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 89ms/step - accuracy: 0.9398 - loss: 0.1615 - val_accuracy: 0.9273 - val_loss: 0.2095\n",
            "Epoch 192/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.1438 - val_accuracy: 0.9268 - val_loss: 0.2103\n",
            "Epoch 193/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 86ms/step - accuracy: 0.9406 - loss: 0.1564 - val_accuracy: 0.9329 - val_loss: 0.1963\n",
            "Epoch 194/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9336 - loss: 0.1839 - val_accuracy: 0.9328 - val_loss: 0.1965\n",
            "Epoch 195/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9412 - loss: 0.1553 - val_accuracy: 0.9302 - val_loss: 0.1956\n",
            "Epoch 196/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9336 - loss: 0.1537 - val_accuracy: 0.9296 - val_loss: 0.1984\n",
            "Epoch 197/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.9422 - loss: 0.1588 - val_accuracy: 0.9262 - val_loss: 0.2113\n",
            "Epoch 198/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9414 - loss: 0.1559 - val_accuracy: 0.9253 - val_loss: 0.2113\n",
            "Epoch 199/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.9397 - loss: 0.1598 - val_accuracy: 0.9358 - val_loss: 0.1861\n",
            "Epoch 200/200\n",
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9492 - loss: 0.1108 - val_accuracy: 0.9347 - val_loss: 0.1868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_trace(x,y,ylabel,color):\n",
        "  # trace = go.Scatter(x=x, y=y, name=ylabel, marker=dict(color=color), mode='markers+lines', text=x)\n",
        "  trace = go.Scatter(x=list(x), y=y, name=ylabel, marker=dict(color=color), mode='markers+lines', text=list(x))\n",
        "  return trace\n",
        "\n",
        "def plot_accuracy_and_loss(train_model):\n",
        "  hist = train_model.history\n",
        "  acc = hist['accuracy']\n",
        "  val_acc = hist['val_accuracy']\n",
        "  loss = hist['loss']\n",
        "  val_loss = hist['val_loss']\n",
        "  epochs = range(1,len(acc)+1)\n",
        "\n",
        "  trace_ta = create_trace(epochs,acc,'Training Accuracy','green')\n",
        "  trace_ts = create_trace(epochs,val_acc,'Validation Accuracy','red')\n",
        "  trace_tl = create_trace(epochs,loss,'Training Loss','blue')\n",
        "  trace_vl = create_trace(epochs,val_loss,'Validation Loss','magenta')\n",
        "\n",
        "  fig = subplots.make_subplots(rows=1,cols=2,subplot_titles=('Training and Validation Accuracy','Training and Validation Loss'))\n",
        "  fig.append_trace(trace_ta,1,1)\n",
        "  fig.append_trace(trace_ts,1,1)\n",
        "  fig.append_trace(trace_tl,1,2)\n",
        "  fig.append_trace(trace_vl,1,2)\n",
        "  fig['layout']['xaxis'].update(title='Epoch')\n",
        "  fig['layout']['xaxis2'].update(title='Epoch')\n",
        "  fig['layout']['yaxis'].update(title='Accuracy',range=[0,1])\n",
        "  fig['layout']['yaxis2'].update(title='Loss',range=[0,1])\n",
        "\n",
        "  plotly.offline.iplot(fig,filename='accuracy-loss')"
      ],
      "metadata": {
        "id": "5dGSpj8qKOBY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracy_and_loss(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "c5QdKMJMKPnc",
        "outputId": "bcebc1e6-17aa-4255-8afb-5c55db21c52c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"6d20b5b3-a793-4078-8b43-fd6ad42cec86\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6d20b5b3-a793-4078-8b43-fd6ad42cec86\")) {                    Plotly.newPlot(                        \"6d20b5b3-a793-4078-8b43-fd6ad42cec86\",                        [{\"marker\":{\"color\":\"green\"},\"mode\":\"markers+lines\",\"name\":\"Training Accuracy\",\"text\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\",\"151\",\"152\",\"153\",\"154\",\"155\",\"156\",\"157\",\"158\",\"159\",\"160\",\"161\",\"162\",\"163\",\"164\",\"165\",\"166\",\"167\",\"168\",\"169\",\"170\",\"171\",\"172\",\"173\",\"174\",\"175\",\"176\",\"177\",\"178\",\"179\",\"180\",\"181\",\"182\",\"183\",\"184\",\"185\",\"186\",\"187\",\"188\",\"189\",\"190\",\"191\",\"192\",\"193\",\"194\",\"195\",\"196\",\"197\",\"198\",\"199\",\"200\"],\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200],\"xaxis\":\"x\",\"y\":[0.7058269381523132,0.74609375,0.7856274843215942,0.859375,0.8147411346435547,0.8359375,0.8312458395957947,0.83203125,0.84375,0.87109375,0.8526516556739807,0.8515625,0.8613228797912598,0.859375,0.8677111268043518,0.87890625,0.8700150847434998,0.91015625,0.8732196688652039,0.88671875,0.8780161142349243,0.890625,0.8806551694869995,0.8984375,0.8857448101043701,0.89453125,0.8844252824783325,0.91796875,0.8908344507217407,0.87890625,0.8912533521652222,0.87890625,0.8908344507217407,0.90234375,0.8935782313346863,0.890625,0.8957146406173706,0.875,0.8977882266044617,0.9140625,0.8999036550521851,0.8984375,0.8997570276260376,0.89453125,0.9014326333999634,0.8828125,0.9011394381523132,0.8984375,0.901348888874054,0.9375,0.9057263731956482,0.921875,0.905705451965332,0.91015625,0.9081559777259827,0.9140625,0.9078208804130554,0.91796875,0.9113815426826477,0.89453125,0.910020112991333,0.91015625,0.9101876616477966,0.90625,0.9125125408172607,0.90234375,0.9155077338218689,0.92578125,0.9147955775260925,0.921875,0.9119051694869995,0.9453125,0.9151097536087036,0.9453125,0.9161989092826843,0.921875,0.9189007878303528,0.8984375,0.9193825125694275,0.9140625,0.9176022410392761,0.91796875,0.9196966886520386,0.91015625,0.9194034934043884,0.93359375,0.9200108647346497,0.9453125,0.9191730618476868,0.91796875,0.9216864705085754,0.90625,0.9218959212303162,0.91796875,0.9219797253608704,0.92578125,0.9232783317565918,0.90234375,0.9228803515434265,0.91796875,0.9221891760826111,0.890625,0.9248911142349243,0.890625,0.9253100156784058,0.90625,0.9237600564956665,0.92578125,0.925917387008667,0.9296875,0.9266504645347595,0.90625,0.9292476773262024,0.92578125,0.9283260703086853,0.9609375,0.9290382266044617,0.9140625,0.9284726977348328,0.94140625,0.9279909729957581,0.9453125,0.9302530288696289,0.9375,0.9298550486564636,0.9296875,0.9315306544303894,0.94140625,0.9330387115478516,0.8984375,0.9296665787696838,0.9296875,0.9318448305130005,0.9375,0.9318867325782776,0.921875,0.9315934777259827,0.9140625,0.9325150847434998,0.9609375,0.9316353797912598,0.9296875,0.9327873587608337,0.9375,0.933457612991333,0.91796875,0.9345257878303528,0.9375,0.9330177903175354,0.9140625,0.9341068863868713,0.9375,0.935154139995575,0.91015625,0.9334785342216492,0.953125,0.9368088245391846,0.9375,0.9354054927825928,0.9453125,0.9356358647346497,0.94921875,0.9352169632911682,0.91796875,0.9366621971130371,0.9453125,0.9360338449478149,0.91796875,0.936955451965332,0.9375,0.9364108443260193,0.9296875,0.9372696280479431,0.93359375,0.9378769993782043,0.8984375,0.9394059777259827,0.92578125,0.9384844303131104,0.9296875,0.9394897818565369,0.93359375,0.9395526051521301,0.953125,0.9396364092826843,0.9453125,0.9396573305130005,0.94921875,0.9396783113479614,0.96875,0.9389661550521851,0.9375,0.9397201538085938,0.93359375,0.9401809573173523,0.93359375,0.941814661026001,0.94140625,0.9409559369087219,0.94921875],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\"},\"mode\":\"markers+lines\",\"name\":\"Validation Accuracy\",\"text\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\",\"151\",\"152\",\"153\",\"154\",\"155\",\"156\",\"157\",\"158\",\"159\",\"160\",\"161\",\"162\",\"163\",\"164\",\"165\",\"166\",\"167\",\"168\",\"169\",\"170\",\"171\",\"172\",\"173\",\"174\",\"175\",\"176\",\"177\",\"178\",\"179\",\"180\",\"181\",\"182\",\"183\",\"184\",\"185\",\"186\",\"187\",\"188\",\"189\",\"190\",\"191\",\"192\",\"193\",\"194\",\"195\",\"196\",\"197\",\"198\",\"199\",\"200\"],\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200],\"xaxis\":\"x\",\"y\":[0.15208333730697632,0.12675000727176666,0.3049166798591614,0.2984166741371155,0.6521666646003723,0.6487500071525574,0.8637499809265137,0.8504166603088379,0.8479999899864197,0.8544166684150696,0.8924166560173035,0.8983333110809326,0.8867499828338623,0.8930833339691162,0.8951666951179504,0.8927500247955322,0.9041666388511658,0.9058333039283752,0.8960833549499512,0.8939999938011169,0.9017500281333923,0.8998333215713501,0.9076666831970215,0.9073333144187927,0.909166693687439,0.9103333353996277,0.9006666541099548,0.8988333344459534,0.9144999980926514,0.9149166941642761,0.906166672706604,0.9069166779518127,0.9206666946411133,0.9190833568572998,0.9164999723434448,0.9185000061988831,0.9057499766349792,0.9078333377838135,0.9071666598320007,0.9082499742507935,0.9149166941642761,0.9161666631698608,0.9070833325386047,0.9099166393280029,0.909250020980835,0.9117500185966492,0.9258333444595337,0.9252499938011169,0.9120833277702332,0.9115833044052124,0.9230833053588867,0.9235833287239075,0.9239166378974915,0.9240833520889282,0.9214166402816772,0.9209166765213013,0.9178333282470703,0.9174166917800903,0.9290833473205566,0.9292500019073486,0.921500027179718,0.9239166378974915,0.9169166684150696,0.9163333177566528,0.9262499809265137,0.9263333082199097,0.9173333048820496,0.9177500009536743,0.9169999957084656,0.9182500243186951,0.9173333048820496,0.9194999933242798,0.9160833358764648,0.9160000085830688,0.9224166870117188,0.9212499856948853,0.9269166588783264,0.9258333444595337,0.9285833239555359,0.9287499785423279,0.9011666774749756,0.8990833163261414,0.9300833344459534,0.9301666617393494,0.921999990940094,0.9207500219345093,0.92208331823349,0.921833336353302,0.9210833311080933,0.9228333234786987,0.9223333597183228,0.9209166765213013,0.9113333225250244,0.9107499718666077,0.9204166531562805,0.9190833568572998,0.9178333282470703,0.9178333282470703,0.9194999933242798,0.9205833077430725,0.9176666736602783,0.9174166917800903,0.9183333516120911,0.9184166789054871,0.9179999828338623,0.9182500243186951,0.921999990940094,0.9236666560173035,0.9282500147819519,0.9279166460037231,0.9261666536331177,0.9254166483879089,0.9257500171661377,0.9252499938011169,0.9258333444595337,0.9254166483879089,0.9242500066757202,0.9235000014305115,0.9337499737739563,0.9330000281333923,0.9116666913032532,0.9129166603088379,0.9192500114440918,0.9192500114440918,0.9126666784286499,0.9124166369438171,0.9158333539962769,0.9154166579246521,0.9284999966621399,0.9274166822433472,0.9255833625793457,0.9272500276565552,0.9286666512489319,0.9284166693687439,0.9231666922569275,0.9235000014305115,0.9197499752044678,0.9206666946411133,0.9276666641235352,0.9277499914169312,0.9315833449363708,0.9326666593551636,0.9254999756813049,0.925000011920929,0.9254166483879089,0.9257500171661377,0.9272500276565552,0.9279166460037231,0.9224166870117188,0.9235000014305115,0.9317499995231628,0.9317499995231628,0.9369999766349792,0.937250018119812,0.9252499938011169,0.9255833625793457,0.9309999942779541,0.9302499890327454,0.9239166378974915,0.924833357334137,0.9326666593551636,0.9319999814033508,0.9322500228881836,0.9332500100135803,0.9269166588783264,0.9265000224113464,0.92208331823349,0.921500027179718,0.9353333115577698,0.9353333115577698,0.9204166531562805,0.9204999804496765,0.9324166774749756,0.934249997138977,0.9279166460037231,0.9284166693687439,0.9271666407585144,0.9259999990463257,0.9304166436195374,0.9290000200271606,0.9317499995231628,0.9303333163261414,0.9334166646003723,0.9330000281333923,0.9228333234786987,0.922249972820282,0.9292500019073486,0.9293333292007446,0.9323333501815796,0.9336666464805603,0.9272500276565552,0.9267500042915344,0.9329166412353516,0.9328333139419556,0.9302499890327454,0.9295833110809326,0.9261666536331177,0.9253333210945129,0.9357500076293945,0.9346666932106018],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\"},\"mode\":\"markers+lines\",\"name\":\"Training Loss\",\"text\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\",\"151\",\"152\",\"153\",\"154\",\"155\",\"156\",\"157\",\"158\",\"159\",\"160\",\"161\",\"162\",\"163\",\"164\",\"165\",\"166\",\"167\",\"168\",\"169\",\"170\",\"171\",\"172\",\"173\",\"174\",\"175\",\"176\",\"177\",\"178\",\"179\",\"180\",\"181\",\"182\",\"183\",\"184\",\"185\",\"186\",\"187\",\"188\",\"189\",\"190\",\"191\",\"192\",\"193\",\"194\",\"195\",\"196\",\"197\",\"198\",\"199\",\"200\"],\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200],\"xaxis\":\"x2\",\"y\":[0.7928501963615417,0.6449417471885681,0.5626956820487976,0.3895609378814697,0.4899941086769104,0.4333253502845764,0.4502435028553009,0.4630379378795624,0.41622692346572876,0.37236571311950684,0.394248902797699,0.3936043381690979,0.3729366958141327,0.39338237047195435,0.3573370575904846,0.3643600344657898,0.34916093945503235,0.2699827551841736,0.3359835147857666,0.3407554626464844,0.32808056473731995,0.2743528485298157,0.3215372860431671,0.2949870228767395,0.31058916449546814,0.30910733342170715,0.310109406709671,0.2776607573032379,0.29844945669174194,0.2745821177959442,0.29362112283706665,0.32366743683815,0.2911175787448883,0.2591315507888794,0.28338423371315,0.33393537998199463,0.28052186965942383,0.28852662444114685,0.27789533138275146,0.21734127402305603,0.27147889137268066,0.2913174629211426,0.26983144879341125,0.2373407781124115,0.26570191979408264,0.37284231185913086,0.26331639289855957,0.2921145558357239,0.2618759274482727,0.21403171122074127,0.25652414560317993,0.22964125871658325,0.25272518396377563,0.3007006347179413,0.24898897111415863,0.22579799592494965,0.24949073791503906,0.21526649594306946,0.24329277873039246,0.3073650598526001,0.2456853687763214,0.22431297600269318,0.2417193502187729,0.24571526050567627,0.23788370192050934,0.24968086183071136,0.23169542849063873,0.2410898208618164,0.23141956329345703,0.23630601167678833,0.23473143577575684,0.14876870810985565,0.22741220891475677,0.17012539505958557,0.22726663947105408,0.22838784754276276,0.22309821844100952,0.33497029542922974,0.21917301416397095,0.1953587681055069,0.22363029420375824,0.2260877937078476,0.2191009521484375,0.23852533102035522,0.2169256955385208,0.1938355267047882,0.2156241536140442,0.16048137843608856,0.21695081889629364,0.23716005682945251,0.21290403604507446,0.19575124979019165,0.21107330918312073,0.22960856556892395,0.20891429483890533,0.20212024450302124,0.20774833858013153,0.2476823627948761,0.20852090418338776,0.20536202192306519,0.20693795382976532,0.31227144598960876,0.20400260388851166,0.2535083293914795,0.2019706517457962,0.22278115153312683,0.20386862754821777,0.1750093698501587,0.20046880841255188,0.24361048638820648,0.1983233243227005,0.2415389120578766,0.19552117586135864,0.18754708766937256,0.1973450481891632,0.12674105167388916,0.19214493036270142,0.21631953120231628,0.19463448226451874,0.186717689037323,0.19252492487430573,0.19297662377357483,0.1897226721048355,0.19961851835250854,0.19166524708271027,0.19743454456329346,0.1864287108182907,0.13350510597229004,0.18285782635211945,0.26664119958877563,0.18611375987529755,0.17118024826049805,0.1847507208585739,0.18312017619609833,0.1866915225982666,0.20503078401088715,0.18329906463623047,0.18678629398345947,0.18136531114578247,0.1488880217075348,0.18182921409606934,0.17918024957180023,0.18033093214035034,0.1575554460287094,0.1802021712064743,0.21128007769584656,0.17881718277931213,0.163587287068367,0.1801680475473404,0.2099294364452362,0.17652711272239685,0.15608209371566772,0.17405597865581512,0.23684927821159363,0.17777058482170105,0.13513025641441345,0.1701868325471878,0.17933958768844604,0.17533423006534576,0.17101536691188812,0.17321902513504028,0.14765965938568115,0.1729632169008255,0.21666236221790314,0.1706579476594925,0.13759006559848785,0.17296452820301056,0.23897382616996765,0.17073160409927368,0.14907559752464294,0.16922171413898468,0.1770501285791397,0.16825933754444122,0.15694008767604828,0.16846701502799988,0.2324327528476715,0.1657206416130066,0.16911309957504272,0.16462357342243195,0.19159887731075287,0.1670633852481842,0.18085047602653503,0.16283102333545685,0.17708632349967957,0.16013167798519135,0.16438764333724976,0.162883922457695,0.11968231201171875,0.15804697573184967,0.07379840314388275,0.16274471580982208,0.1437511146068573,0.15998061001300812,0.18392586708068848,0.15984883904457092,0.15374833345413208,0.15902112424373627,0.15588052570819855,0.15914788842201233,0.11083604395389557],\"yaxis\":\"y2\",\"type\":\"scatter\"},{\"marker\":{\"color\":\"magenta\"},\"mode\":\"markers+lines\",\"name\":\"Validation Loss\",\"text\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\",\"151\",\"152\",\"153\",\"154\",\"155\",\"156\",\"157\",\"158\",\"159\",\"160\",\"161\",\"162\",\"163\",\"164\",\"165\",\"166\",\"167\",\"168\",\"169\",\"170\",\"171\",\"172\",\"173\",\"174\",\"175\",\"176\",\"177\",\"178\",\"179\",\"180\",\"181\",\"182\",\"183\",\"184\",\"185\",\"186\",\"187\",\"188\",\"189\",\"190\",\"191\",\"192\",\"193\",\"194\",\"195\",\"196\",\"197\",\"198\",\"199\",\"200\"],\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200],\"xaxis\":\"x2\",\"y\":[3.441138982772827,3.454803943634033,2.3042287826538086,2.3307101726531982,1.0434008836746216,1.0633511543273926,0.36041581630706787,0.3967829644680023,0.40642645955085754,0.3904050290584564,0.28720808029174805,0.2771753668785095,0.3071463704109192,0.2882058620452881,0.28437262773513794,0.2901220917701721,0.2520788311958313,0.24986529350280762,0.2787996530532837,0.2855204641819,0.2617759704589844,0.26673057675361633,0.2469472587108612,0.2480553537607193,0.24261270463466644,0.2404623180627823,0.2652643918991089,0.27079519629478455,0.23115448653697968,0.23250707983970642,0.252268522977829,0.25008583068847656,0.21742935478687286,0.21821410953998566,0.22534580528736115,0.22214941680431366,0.25391241908073425,0.2500825524330139,0.2586161196231842,0.2585999369621277,0.23284927010536194,0.2304624617099762,0.2487320601940155,0.24184155464172363,0.24107961356639862,0.23661965131759644,0.20023030042648315,0.20039725303649902,0.23621734976768494,0.23664188385009766,0.20996342599391937,0.20853224396705627,0.2055945247411728,0.2045111507177353,0.21069546043872833,0.21107222139835358,0.2235884964466095,0.2253802865743637,0.1978123039007187,0.19686628878116608,0.2117072194814682,0.2085646390914917,0.23167254030704498,0.23159979283809662,0.20204579830169678,0.2028791904449463,0.22775530815124512,0.22790411114692688,0.23528289794921875,0.22969268262386322,0.22505460679531097,0.21995031833648682,0.22950239479541779,0.23240961134433746,0.21683147549629211,0.2179868370294571,0.19509124755859375,0.19793088734149933,0.19786550104618073,0.1970634013414383,0.2794955372810364,0.2876379191875458,0.19347792863845825,0.19208353757858276,0.21609985828399658,0.21946793794631958,0.21241030097007751,0.21218419075012207,0.21732619404792786,0.21497564017772675,0.21309179067611694,0.2169497311115265,0.2553107738494873,0.25444161891937256,0.22551549971103668,0.22886162996292114,0.22984883189201355,0.22977618873119354,0.2179570496082306,0.218114972114563,0.2290307581424713,0.22987861931324005,0.22936278581619263,0.23035980761051178,0.23805810511112213,0.23604390025138855,0.21380849182605743,0.21313609182834625,0.204610213637352,0.20268048346042633,0.2112845480442047,0.21096159517765045,0.20395700633525848,0.20707251131534576,0.2029467523097992,0.2043173462152481,0.21385884284973145,0.21464934945106506,0.1885192096233368,0.19213277101516724,0.25355264544487,0.25031137466430664,0.22676169872283936,0.22604747116565704,0.2412990778684616,0.24298782646656036,0.24726365506649017,0.24866904318332672,0.20705579221248627,0.2107023149728775,0.2110314518213272,0.2071409374475479,0.2032177746295929,0.20270615816116333,0.21899475157260895,0.2195693403482437,0.2229045033454895,0.2192482054233551,0.2077939212322235,0.20418158173561096,0.19084954261779785,0.1886807084083557,0.21171621978282928,0.21480920910835266,0.2074728161096573,0.20728936791419983,0.2051241397857666,0.2056102156639099,0.2223016321659088,0.22009186446666718,0.19390669465065002,0.1946377158164978,0.17893429100513458,0.17815761268138885,0.20707179605960846,0.20588964223861694,0.18942999839782715,0.18969625234603882,0.21310198307037354,0.21065057814121246,0.19099168479442596,0.19164040684700012,0.19133298099040985,0.1914244443178177,0.20804822444915771,0.2080342024564743,0.22613315284252167,0.22858542203903198,0.1847025603055954,0.18451759219169617,0.22710257768630981,0.22906392812728882,0.19155186414718628,0.18854378163814545,0.2094147503376007,0.20972420275211334,0.21426765620708466,0.21736960113048553,0.19985036551952362,0.20389734208583832,0.19562754034996033,0.19872385263442993,0.1917555183172226,0.19157403707504272,0.22183272242546082,0.22621223330497742,0.20949652791023254,0.21159139275550842,0.19315634667873383,0.19216229021549225,0.20950277149677277,0.21034550666809082,0.19631889462471008,0.19647946953773499,0.1956038773059845,0.198400616645813,0.21127311885356903,0.21134783327579498,0.1861332803964615,0.18681229650974274],\"yaxis\":\"y2\",\"type\":\"scatter\"}],                        {\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Training and Validation Accuracy\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Training and Validation Loss\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"range\":[0,1],\"title\":{\"text\":\"Accuracy\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"range\":[0,1],\"title\":{\"text\":\"Loss\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6d20b5b3-a793-4078-8b43-fd6ad42cec86');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(test_data, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlT9LNhGKRJO",
        "outputId": "2aedaf70-5cd7-4536-b9b9-c37b06454f26"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.1943226009607315\n",
            "Test accuracy: 0.9344000220298767\n"
          ]
        }
      ]
    }
  ]
}